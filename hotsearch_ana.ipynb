{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31939371",
   "metadata": {},
   "source": [
    "# å¯é€‰æ‹©æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd48354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Run @ 2025-12-29 19:23:39 =====\n",
      "Provider=deepseek | Fetched 30 hot topics. Model returned 7 bullish / 4 bearish.\n",
      "\n",
      "ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic</th>\n",
       "      <th>industries</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Aè‚¡åˆ›å¹´å†…è¿æ¶¨çºªå½• æ˜¯æ–°èµ·ç‚¹å—</td>\n",
       "      <td>Aè‚¡å¸‚åœº</td>\n",
       "      <td>å¸‚åœºæƒ…ç»ªææŒ¯ï¼Œå¯èƒ½æ¨åŠ¨çŸ­æœŸä¸Šæ¶¨ã€‚</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>æ•°å­—äººæ°‘å¸è¿æ¥é‡å¤§è°ƒæ•´</td>\n",
       "      <td>é‡‘èç§‘æŠ€ï¼Œæ•°å­—è´§å¸</td>\n",
       "      <td>æ”¿ç­–åˆ©å¥½ï¼Œä¿ƒè¿›ç›¸å…³æŠ€æœ¯åº”ç”¨å’Œæ¨å¹¿ã€‚</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>2026å¹´èµ·æ•°å­—äººæ°‘å¸ä½™é¢æŒ‰å­˜æ¬¾è®¡æ¯</td>\n",
       "      <td>é‡‘èç§‘æŠ€ï¼Œæ•°å­—è´§å¸</td>\n",
       "      <td>å¢åŠ å¸å¼•åŠ›ï¼Œåˆ©å¥½æ•°å­—è´§å¸ç”Ÿæ€å‘å±•ã€‚</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>æ˜å¹´èµ·æˆ‘å›½è°ƒæ•´éƒ¨åˆ†å•†å“å…³ç¨</td>\n",
       "      <td>è¿›å‡ºå£è´¸æ˜“</td>\n",
       "      <td>å…³ç¨è°ƒæ•´å¯èƒ½é™ä½è¿›å£æˆæœ¬ï¼Œåˆºæ¿€æ¶ˆè´¹ã€‚</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2025â€œä¸‰å†œâ€æˆç»©å•</td>\n",
       "      <td>å†œä¸š</td>\n",
       "      <td>æ”¿ç­–æ”¯æŒæˆ–ä¸šç»©æå‡ï¼Œåˆ©å¥½å†œä¸šæ¿å—ã€‚</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>æŠ•èµ„äººè¹²å®ˆå¤§ç–†æ¥¼ä¸‹æŠ¢äºº</td>\n",
       "      <td>ç§‘æŠ€ï¼Œæ— äººæœº</td>\n",
       "      <td>äººæ‰ç«äº‰æ¿€çƒˆï¼Œåæ˜ è¡Œä¸šé«˜å¢é•¿æ½œåŠ›ã€‚</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>å¤§å­¦ç”Ÿç¬¬ä¸€ä»½å·¥ä½œåº”è¯¥é€‰å¤®å›½ä¼å—</td>\n",
       "      <td>å¤®å›½ä¼</td>\n",
       "      <td>å…³æ³¨åº¦æå‡ï¼Œå¯èƒ½å¢å¼ºæŠ•èµ„è€…ä¿¡å¿ƒã€‚</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank               topic industries           mechanism  confidence\n",
       "0    21     Aè‚¡åˆ›å¹´å†…è¿æ¶¨çºªå½• æ˜¯æ–°èµ·ç‚¹å—       Aè‚¡å¸‚åœº    å¸‚åœºæƒ…ç»ªææŒ¯ï¼Œå¯èƒ½æ¨åŠ¨çŸ­æœŸä¸Šæ¶¨ã€‚        0.70\n",
       "1    18         æ•°å­—äººæ°‘å¸è¿æ¥é‡å¤§è°ƒæ•´  é‡‘èç§‘æŠ€ï¼Œæ•°å­—è´§å¸   æ”¿ç­–åˆ©å¥½ï¼Œä¿ƒè¿›ç›¸å…³æŠ€æœ¯åº”ç”¨å’Œæ¨å¹¿ã€‚        0.80\n",
       "2    22  2026å¹´èµ·æ•°å­—äººæ°‘å¸ä½™é¢æŒ‰å­˜æ¬¾è®¡æ¯  é‡‘èç§‘æŠ€ï¼Œæ•°å­—è´§å¸   å¢åŠ å¸å¼•åŠ›ï¼Œåˆ©å¥½æ•°å­—è´§å¸ç”Ÿæ€å‘å±•ã€‚        0.75\n",
       "3    28       æ˜å¹´èµ·æˆ‘å›½è°ƒæ•´éƒ¨åˆ†å•†å“å…³ç¨      è¿›å‡ºå£è´¸æ˜“  å…³ç¨è°ƒæ•´å¯èƒ½é™ä½è¿›å£æˆæœ¬ï¼Œåˆºæ¿€æ¶ˆè´¹ã€‚        0.60\n",
       "4     3         2025â€œä¸‰å†œâ€æˆç»©å•         å†œä¸š   æ”¿ç­–æ”¯æŒæˆ–ä¸šç»©æå‡ï¼Œåˆ©å¥½å†œä¸šæ¿å—ã€‚        0.65\n",
       "5    24         æŠ•èµ„äººè¹²å®ˆå¤§ç–†æ¥¼ä¸‹æŠ¢äºº     ç§‘æŠ€ï¼Œæ— äººæœº   äººæ‰ç«äº‰æ¿€çƒˆï¼Œåæ˜ è¡Œä¸šé«˜å¢é•¿æ½œåŠ›ã€‚        0.70\n",
       "6     9     å¤§å­¦ç”Ÿç¬¬ä¸€ä»½å·¥ä½œåº”è¯¥é€‰å¤®å›½ä¼å—        å¤®å›½ä¼    å…³æ³¨åº¦æå‡ï¼Œå¯èƒ½å¢å¼ºæŠ•èµ„è€…ä¿¡å¿ƒã€‚        0.50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic</th>\n",
       "      <th>industries</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ä¸­æ–¹è¦æ±‚å½»æŸ¥ä¸­å·´å…¬å›­æ‹†é™¤äº‹ä»¶</td>\n",
       "      <td>ä¸­å·´å…³ç³»ç›¸å…³è¡Œä¸š</td>\n",
       "      <td>å¤–äº¤ç´§å¼ å¯èƒ½å½±å“åŒè¾¹è´¸æ˜“å’ŒæŠ•èµ„ã€‚</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>é¤é¥®å•†æˆ·æ„ŸæŸ“è‰¾æ»‹ç—…ï¼Ÿè¾½å®å–€å·¦è¾Ÿè°£</td>\n",
       "      <td>é¤é¥®ä¸š</td>\n",
       "      <td>è´Ÿé¢è°£è¨€å¯èƒ½çŸ­æœŸå†²å‡»æ¶ˆè´¹è€…ä¿¡å¿ƒã€‚</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>ä¿„ä¸ºä½•å°†åœ¨ä¿„æ—¥æ•æ„Ÿåœ°ç‚¹å†›æ¼”ä¸¤ä¸ªæœˆ</td>\n",
       "      <td>åœ°ç¼˜æ”¿æ²»æ•æ„Ÿè¡Œä¸š</td>\n",
       "      <td>åœ°ç¼˜ç´§å¼ åŠ å‰§ï¼Œå¢åŠ å¸‚åœºä¸ç¡®å®šæ€§ã€‚</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>å°å†›å¦å…‹ä¸Šè¡—ä¸ä¹…å°±èµ·ç«å†’ç™½çƒŸ</td>\n",
       "      <td>å†›å·¥</td>\n",
       "      <td>äº‹ä»¶å¯èƒ½å¼•å‘å¯¹å†›å·¥äº§å“è´¨é‡æ‹…å¿§ã€‚</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank             topic industries         mechanism  confidence\n",
       "0     2    ä¸­æ–¹è¦æ±‚å½»æŸ¥ä¸­å·´å…¬å›­æ‹†é™¤äº‹ä»¶   ä¸­å·´å…³ç³»ç›¸å…³è¡Œä¸š  å¤–äº¤ç´§å¼ å¯èƒ½å½±å“åŒè¾¹è´¸æ˜“å’ŒæŠ•èµ„ã€‚        0.60\n",
       "1    11  é¤é¥®å•†æˆ·æ„ŸæŸ“è‰¾æ»‹ç—…ï¼Ÿè¾½å®å–€å·¦è¾Ÿè°£        é¤é¥®ä¸š  è´Ÿé¢è°£è¨€å¯èƒ½çŸ­æœŸå†²å‡»æ¶ˆè´¹è€…ä¿¡å¿ƒã€‚        0.55\n",
       "2    16  ä¿„ä¸ºä½•å°†åœ¨ä¿„æ—¥æ•æ„Ÿåœ°ç‚¹å†›æ¼”ä¸¤ä¸ªæœˆ   åœ°ç¼˜æ”¿æ²»æ•æ„Ÿè¡Œä¸š  åœ°ç¼˜ç´§å¼ åŠ å‰§ï¼Œå¢åŠ å¸‚åœºä¸ç¡®å®šæ€§ã€‚        0.65\n",
       "3    17    å°å†›å¦å…‹ä¸Šè¡—ä¸ä¹…å°±èµ·ç«å†’ç™½çƒŸ         å†›å·¥  äº‹ä»¶å¯èƒ½å¼•å‘å¯¹å†›å·¥äº§å“è´¨é‡æ‹…å¿§ã€‚        0.50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ å·²ä¿å­˜ Excelï¼š/Users/pz/VScode/Stock_Ana/hotsearch_stock_outputs/hotsearch_20251229_192339.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ä»Šæ—¥å¤´æ¡çƒ­æ¦œ -> (Qwen / DeepSeek å¯åˆ‡æ¢) -> åˆ©å¤š/åˆ©ç©ºå±•ç¤º\n",
    "# ç¨³å®šç‰ˆï¼š\n",
    "#  - å¼ºåˆ¶ JSON è¾“å‡ºï¼ˆresponse_format=json_objectï¼‰\n",
    "#  - æ ‡é¢˜/æ–‡æœ¬å‡€åŒ–ï¼ˆé¿å… ASCII åŒå¼•å·ç ´å JSONï¼‰\n",
    "#  - æœ¬åœ°ä¸¥æ ¼æ ¡éªŒ + é‡è¯•ï¼ˆåŒºåˆ†ï¼š429/5xx/ç©ºcontent/æˆªæ–­/è§£æå¤±è´¥ï¼‰\n",
    "#  - æˆªæ–­è‡ªé€‚åº”ï¼šå…ˆåŠ  max_tokensï¼Œå†å‡è¾“å‡ºæ¡æ•°\n",
    "#  - å¯é€‰å¼¹çª—ï¼ˆæµè§ˆå™¨æ‰“å¼€ HTMLï¼‰\n",
    "#  - æ¯æ¬¡è¿è¡Œä¿å­˜ Excelï¼ˆåŒæ–‡ä»¶ä¸¤å¼  sheetï¼šåˆ©å¤š/åˆ©ç©ºï¼›æ–‡ä»¶å=æ—¶é—´æˆ³é¿å…é‡å¤ï¼‰\n",
    "# ==========================================\n",
    "\n",
    "# =========================\n",
    "# A) å‚æ•°åŒºï¼ˆä½ ä¸»è¦æ”¹è¿™é‡Œï¼‰\n",
    "# =========================\n",
    "CONFIG = {\n",
    "    # âœ… é€‰æ‹©æ¨¡å‹æä¾›å•†ï¼š \"deepseek\" æˆ– \"qwen\"\n",
    "    \"PROVIDER\": \"deepseek\",\n",
    "\n",
    "    # å®šæ—¶è¿è¡Œ\n",
    "    \"ENABLE_SCHEDULER\": False,\n",
    "    \"INTERVAL_MINUTES\": 30,\n",
    "\n",
    "    # çƒ­æœæŠ“å–\n",
    "    \"TOP_K\": 30,\n",
    "    \"TOUTIAO_TIMEOUT\": 12,\n",
    "\n",
    "    # Qwenï¼ˆDashScope OpenAI å…¼å®¹æ¥å£ï¼‰\n",
    "    \"QWEN_API_KEY\": \"sk-b8a5d51908184663854d1b5c8e73e25e\",\n",
    "    \"QWEN_MODEL\": \"qwen-plus\",\n",
    "    \"QWEN_BASE_URL\": \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    \"QWEN_TIMEOUT\": 60,\n",
    "\n",
    "    # DeepSeekï¼ˆOpenAI å…¼å®¹æ¥å£ï¼‰\n",
    "    \"DEEPSEEK_API_KEY\": \"sk-1d213aa830694d2ba292a75d06cd5d77\",\n",
    "    \"DEEPSEEK_MODEL\": \"deepseek-chat\",\n",
    "    \"DEEPSEEK_BASE_URL\": \"https://api.deepseek.com/v1\",\n",
    "    \"DEEPSEEK_TIMEOUT\": 60,\n",
    "\n",
    "    # ç”Ÿæˆå‚æ•°ï¼šä»è¾ƒå°å¼€å§‹ï¼›æ£€æµ‹æˆªæ–­ä¼šè‡ªåŠ¨æŠ¬å‡åˆ° MAX_TOKENS_MAX\n",
    "    \"TEMPERATURE\": 0.0,\n",
    "    \"MAX_TOKENS_START\": 1400,\n",
    "    \"MAX_TOKENS_MAX\": 4200,      # å¤ªå¤§å¯èƒ½è¢«æœåŠ¡ç«¯æ‹’ç»ï¼Œä¼šè‡ªåŠ¨å›é€€\n",
    "\n",
    "    # è¾“å‡ºæ§åˆ¶ï¼šè‹¥å¤šæ¬¡æˆªæ–­ä¼šè‡ªåŠ¨é™ä½æ¡æ•°\n",
    "    \"MAX_ITEMS_EACH_SIDE\": 12,\n",
    "    \"MAX_IGNORED\": 12,\n",
    "    \"MIN_ITEMS_EACH_SIDE\": 5,\n",
    "    \"MIN_IGNORED\": 0,\n",
    "\n",
    "    # é‡è¯•æ§åˆ¶\n",
    "    \"MAX_RETRIES\": 3,\n",
    "    \"BASE_RETRY_SLEEP_SECONDS\": 0.6,\n",
    "    \"MAX_BACKOFF_SECONDS\": 20,\n",
    "\n",
    "    # è°ƒè¯•\n",
    "    \"DEBUG_SHOW_RAW_ON_FAIL\": True,\n",
    "    \"DEBUG_SHOW_API_ERROR_TEXT\": False,\n",
    "\n",
    "    # ç»“æœå±•ç¤ºï¼šå¼¹å‡ºçª—å£\n",
    "    \"ENABLE_POPUP\": True,\n",
    "    \"POPUP_TITLE_PREFIX\": \"çƒ­æœåˆ©å¤š/åˆ©ç©ºåˆ†æ\",\n",
    "\n",
    "    # ç»“æœä¿å­˜ï¼šExcel\n",
    "    \"ENABLE_SAVE_EXCEL\": True,\n",
    "    \"OUTPUT_DIR\": \"./hotsearch_stock_outputs\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# B) ä¾èµ–\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from IPython.display import display  # type: ignore\n",
    "except Exception:\n",
    "    display = None\n",
    "\n",
    "# DataFrame æ˜¾ç¤ºï¼šå…¨éƒ¨è¡Œåˆ— + å®Œæ•´å­—ç¬¦ä¸²\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 0)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) å°å·¥å…·ï¼šæ ‡é¢˜å‡€åŒ–ï¼ˆé¿å… ASCII åŒå¼•å·ç ´å JSONï¼‰\n",
    "# =========================\n",
    "def sanitize_title_for_model(title: str) -> str:\n",
    "    \"\"\"\n",
    "    æŠŠæ ‡é¢˜é‡Œçš„ ASCII åŒå¼•å·æ›¿æ¢æˆä¸­æ–‡å¼•å·ï¼Œé¿å…æ¨¡å‹åŸæ ·æ‹·è´å¯¼è‡´ JSON å­—ç¬¦ä¸²æœªè½¬ä¹‰ã€‚\n",
    "    åŒæ—¶å»æ‰æ§åˆ¶å­—ç¬¦ï¼Œé¿å…å­—ç¬¦ä¸²å†…å‡ºç°éæ³•æ¢è¡Œ/æ§åˆ¶ç¬¦ã€‚\n",
    "    \"\"\"\n",
    "    if title is None:\n",
    "        return \"\"\n",
    "    s = str(title)\n",
    "    s = s.replace('\"', \"â€œ\")\n",
    "    s = re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\", \" \", s)\n",
    "    s = s.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) æŠ“å–ä»Šæ—¥å¤´æ¡çƒ­æ¦œ\n",
    "# =========================\n",
    "def fetch_toutiao_hot(top_k: int = 30, timeout: int = 12) -> List[Dict[str, Any]]:\n",
    "    url = \"https://www.toutiao.com/hot-event/hot-board/?origin=toutiao_pc\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Referer\": \"https://www.toutiao.com/\",\n",
    "        \"Accept\": \"application/json,text/plain,*/*\",\n",
    "    }\n",
    "    r = requests.get(url, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    payload = r.json()\n",
    "\n",
    "    data = payload.get(\"data\")\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Unexpected response schema. Top keys: {list(payload.keys())}\")\n",
    "\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    for i, it in enumerate(data[:top_k], start=1):\n",
    "        title = it.get(\"Title\") or it.get(\"title\") or \"\"\n",
    "        hot_value = it.get(\"HotValue\") or it.get(\"hot_value\") or 0\n",
    "        link = it.get(\"Url\") or it.get(\"url\") or \"\"\n",
    "\n",
    "        try:\n",
    "            hot_value_num = float(hot_value)\n",
    "        except Exception:\n",
    "            hot_value_num = None\n",
    "\n",
    "        items.append({\n",
    "            \"rank\": i,\n",
    "            \"title\": str(title).strip(),\n",
    "            \"hot_value\": hot_value_num,\n",
    "            \"url\": str(link).strip(),\n",
    "        })\n",
    "\n",
    "    return [x for x in items if x[\"title\"]]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) é€šç”¨ï¼šJSON æ¸…ç†/è§£æ/æ ¡éªŒï¼ˆé‡è¦ï¼šä¸æŠŠä¸­æ–‡å¼•å·æ›¿æ¢æˆ ASCII å¼•å·ï¼‰\n",
    "# =========================\n",
    "def clean_text(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"^```(?:json)?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "\n",
    "    s = re.sub(r\"\\bNaN\\b\", \"null\", s)\n",
    "    s = re.sub(r\"\\bInfinity\\b\", \"null\", s)\n",
    "    s = re.sub(r\"\\b-Infinity\\b\", \"null\", s)\n",
    "\n",
    "    s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def strict_parse_json(s: str) -> Dict[str, Any]:\n",
    "    s2 = clean_text(s).strip()\n",
    "    if not (s2.startswith(\"{\") and s2.endswith(\"}\")):\n",
    "        raise ValueError(\"Output is not a pure JSON object (missing { } boundaries).\")\n",
    "    obj = json.loads(s2)\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"JSON is not an object.\")\n",
    "    return obj\n",
    "\n",
    "\n",
    "def validate_result(obj: Dict[str, Any]) -> None:\n",
    "    for k in [\"bullish\", \"bearish\", \"ignored\"]:\n",
    "        if k not in obj:\n",
    "            raise ValueError(f\"Missing key: {k}\")\n",
    "        if not isinstance(obj[k], list):\n",
    "            raise ValueError(f\"Key '{k}' must be a list.\")\n",
    "\n",
    "    def _check_side(side_name: str):\n",
    "        for it in obj.get(side_name, []):\n",
    "            if not isinstance(it, dict):\n",
    "                raise ValueError(f\"{side_name} item not object.\")\n",
    "            for need in [\"rank\", \"topic\", \"industries\", \"mechanism\", \"confidence\"]:\n",
    "                if need not in it:\n",
    "                    raise ValueError(f\"{side_name} missing field: {need}\")\n",
    "            if not isinstance(it[\"industries\"], list):\n",
    "                raise ValueError(f\"{side_name}.industries must be list\")\n",
    "            c = it[\"confidence\"]\n",
    "            if not (isinstance(c, (int, float)) and 0.0 <= float(c) <= 1.0):\n",
    "                raise ValueError(f\"{side_name}.confidence out of range: {c}\")\n",
    "\n",
    "    _check_side(\"bullish\")\n",
    "    _check_side(\"bearish\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Promptï¼ˆçŸ­ + å¼ºçº¦æŸï¼šå®å¯å°‘æ¡ä¹Ÿè¦å®Œæ•´ JSONï¼‰\n",
    "# =========================\n",
    "def build_messages(items: List[Dict[str, Any]], max_each_side: int, max_ignored: int) -> List[Dict[str, str]]:\n",
    "    hot_lines = []\n",
    "    for it in items:\n",
    "        hv = it[\"hot_value\"]\n",
    "        hv_str = f\"{hv:.0f}\" if isinstance(hv, (int, float)) and hv is not None else \"\"\n",
    "        safe_title = sanitize_title_for_model(it[\"title\"])\n",
    "        hot_lines.append(f'{it[\"rank\"]}. {safe_title} (HotValue={hv_str})')\n",
    "\n",
    "    system = (\n",
    "        \"ä½ æ˜¯ä¸¥è°¨çš„ä¸­æ–‡é‡‘èä¿¡æ¯åˆ†æåŠ©æ‰‹ã€‚\"\n",
    "        \"ä½ å¿…é¡»åªè¾“å‡ºjsonå¯¹è±¡ï¼ˆä¸¥æ ¼JSONï¼‰ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚\"\n",
    "        \"å¦‚æœè¾“å‡ºå¯èƒ½è¿‡é•¿ï¼Œå®å¯å‡å°‘æ¡ç›®æ•°ï¼Œä¹Ÿå¿…é¡»ä¿è¯è¾“å‡ºä¸ºå®Œæ•´åˆæ³•JSONã€‚\"\n",
    "    )\n",
    "\n",
    "    user = f\"\"\"\n",
    "è¯·åŸºäºä¸‹é¢çš„â€œä»Šæ—¥å¤´æ¡çƒ­æ¦œæ ‡é¢˜åˆ—è¡¨â€ï¼ŒæŒ‘é€‰å‡ºå¯èƒ½å¼•èµ·ç›¸å…³è¡Œä¸š/æ¿å—çŸ­æœŸè‚¡ä»·æ³¢åŠ¨çš„æ ‡é¢˜ï¼Œå¹¶åˆ†ä¸ºï¼š\n",
    "- bullishï¼ˆåˆ©å¤šï¼‰\n",
    "- bearishï¼ˆåˆ©ç©ºï¼‰\n",
    "- ignoredï¼ˆä¸å¤ªç›¸å…³ï¼‰\n",
    "\n",
    "ä¸¥æ ¼è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š\n",
    "- åªè¾“å‡ºä¸¥æ ¼jsonï¼ˆJSONå¯¹è±¡ï¼‰ï¼Œä¸è¦ markdownï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦ä»»ä½•å‰åç¼€ã€‚\n",
    "- è¾“å‡ºå¿…é¡»ä»¥ {{ å¼€å¤´ï¼Œä»¥ }} ç»“å°¾ã€‚\n",
    "- æ¯ç»„ bullish/bearish æœ€å¤š {max_each_side} æ¡ï¼›ignored æœ€å¤š {max_ignored} æ¡ã€‚\n",
    "- mechanism å¿…é¡»éå¸¸çŸ­ï¼š<= 25 ä¸ªæ±‰å­—ï¼ˆä¸è¦æ¢è¡Œï¼‰ã€‚\n",
    "- ä¸è¦ç¼–é€ å…·ä½“è‚¡ç¥¨ä»£ç ï¼›åªç»™è¡Œä¸š/æ¿å—ã€‚\n",
    "- å¦‚æœæ ‡é¢˜å«æœ‰å¼•å·ï¼Œè¯·ä½¿ç”¨ä¸­æ–‡å¼•å·ï¼ˆâ€œ â€ï¼‰æˆ–å•å¼•å·ï¼Œä¸è¦ä½¿ç”¨ASCIIåŒå¼•å·å­—ç¬¦ \" ã€‚\n",
    "\n",
    "å›ºå®š JSON Schemaï¼ˆå­—æ®µåå¿…é¡»ä¸€è‡´ï¼‰ï¼š\n",
    "{{\n",
    "  \"bullish\": [{{\"rank\": 1, \"topic\": \"...\", \"industries\": [\"...\"], \"mechanism\": \"...\", \"confidence\": 0.0}}],\n",
    "  \"bearish\":  [{{\"rank\": 1, \"topic\": \"...\", \"industries\": [\"...\"], \"mechanism\": \"...\", \"confidence\": 0.0}}],\n",
    "  \"ignored\":  [{{\"rank\": 1, \"topic\": \"...\", \"reason\": \"...\"}}]\n",
    "}}\n",
    "\n",
    "çƒ­æ¦œæ ‡é¢˜åˆ—è¡¨ï¼š\n",
    "{chr(10).join(hot_lines)}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Provider è°ƒç”¨ï¼ˆDeepSeek / Qwenï¼‰\n",
    "# =========================\n",
    "class TemporaryAPIError(Exception):\n",
    "    def __init__(self, msg: str, status_code: Optional[int] = None, retry_after: Optional[float] = None):\n",
    "        super().__init__(msg)\n",
    "        self.status_code = status_code\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "\n",
    "def _post_chat_completions(\n",
    "    base_url: str,\n",
    "    api_key: str,\n",
    "    timeout: int,\n",
    "    body: Dict[str, Any],\n",
    ") -> Dict[str, Any]:\n",
    "    endpoint = base_url.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        r = requests.post(endpoint, headers=headers, json=body, timeout=timeout)\n",
    "    except requests.RequestException as e:\n",
    "        raise TemporaryAPIError(f\"Network error: {e}\", status_code=None) from e\n",
    "\n",
    "    # ä¸´æ—¶é”™è¯¯ï¼šé™æµ/æœåŠ¡ç«¯å¼‚å¸¸\n",
    "    if r.status_code in (429, 500, 502, 503, 504):\n",
    "        retry_after = None\n",
    "        ra = r.headers.get(\"Retry-After\")\n",
    "        if ra:\n",
    "            try:\n",
    "                retry_after = float(ra)\n",
    "            except Exception:\n",
    "                retry_after = None\n",
    "        msg = f\"Temporary HTTP {r.status_code}\"\n",
    "        if CONFIG.get(\"DEBUG_SHOW_API_ERROR_TEXT\"):\n",
    "            msg += f\": {r.text[:1000]}\"\n",
    "        raise TemporaryAPIError(msg, status_code=r.status_code, retry_after=retry_after)\n",
    "\n",
    "    if not r.ok:\n",
    "        raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:1500]}\")\n",
    "\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def call_provider_chat(\n",
    "    provider: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    ") -> Tuple[str, Optional[str], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    è¿”å› (content_text, finish_reason, raw_response)\n",
    "    \"\"\"\n",
    "    provider = provider.lower().strip()\n",
    "    if provider not in (\"deepseek\", \"qwen\"):\n",
    "        raise ValueError(\"CONFIG['PROVIDER'] must be 'deepseek' or 'qwen'.\")\n",
    "\n",
    "    if provider == \"deepseek\":\n",
    "        base_url = CONFIG[\"DEEPSEEK_BASE_URL\"]\n",
    "        api_key = CONFIG[\"DEEPSEEK_API_KEY\"]\n",
    "        model = CONFIG[\"DEEPSEEK_MODEL\"]\n",
    "        timeout = CONFIG[\"DEEPSEEK_TIMEOUT\"]\n",
    "    else:\n",
    "        base_url = CONFIG[\"QWEN_BASE_URL\"]\n",
    "        api_key = CONFIG[\"QWEN_API_KEY\"]\n",
    "        model = CONFIG[\"QWEN_MODEL\"]\n",
    "        timeout = CONFIG[\"QWEN_TIMEOUT\"]\n",
    "\n",
    "    body: Dict[str, Any] = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": False,\n",
    "        \"response_format\": {\"type\": \"json_object\"},  # ä¸¤å®¶éƒ½å°½é‡èµ° JSON mode\n",
    "    }\n",
    "\n",
    "    raw = _post_chat_completions(base_url, api_key, timeout, body)\n",
    "\n",
    "    choice0 = raw[\"choices\"][0]\n",
    "    finish_reason = choice0.get(\"finish_reason\")\n",
    "    msg = choice0[\"message\"]\n",
    "    content = msg.get(\"content\")\n",
    "\n",
    "    # æŸäº›å®ç°å¯èƒ½ tool_calls/argumentsï¼ˆå¯é€‰ï¼‰\n",
    "    tool_calls = msg.get(\"tool_calls\")\n",
    "    if isinstance(tool_calls, list) and tool_calls:\n",
    "        fn = tool_calls[0].get(\"function\", {})\n",
    "        args = fn.get(\"arguments\")\n",
    "        if isinstance(args, str) and args.strip():\n",
    "            return args, finish_reason, raw\n",
    "\n",
    "    if not isinstance(content, str) or not content.strip():\n",
    "        raise TemporaryAPIError(\"Empty content returned (JSON mode).\", status_code=200)\n",
    "\n",
    "    return content, finish_reason, raw\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) é‡è¯•ç­–ç•¥ï¼ˆè‡ªé€‚åº”ï¼šæˆªæ–­->åŠ tokens/å‡æ¡ç›®ï¼‰\n",
    "# =========================\n",
    "def _sleep_with_backoff(attempt: int, base: float, cap: float) -> None:\n",
    "    wait = min(cap, base * (1.7 ** (attempt - 1)))\n",
    "    wait *= (0.85 + 0.3 * random.random())\n",
    "    time.sleep(wait)\n",
    "\n",
    "\n",
    "def analyze_with_retries(items: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    last_text: Optional[str] = None\n",
    "    last_err: Optional[Exception] = None\n",
    "    last_finish: Optional[str] = None\n",
    "\n",
    "    max_tokens = int(CONFIG[\"MAX_TOKENS_START\"])\n",
    "    max_each_side = int(CONFIG[\"MAX_ITEMS_EACH_SIDE\"])\n",
    "    max_ignored = int(CONFIG[\"MAX_IGNORED\"])\n",
    "\n",
    "    for attempt in range(1, CONFIG[\"MAX_RETRIES\"] + 1):\n",
    "        messages = build_messages(items, max_each_side=max_each_side, max_ignored=max_ignored)\n",
    "\n",
    "        try:\n",
    "            text, finish_reason, raw = call_provider_chat(\n",
    "                provider=CONFIG[\"PROVIDER\"],\n",
    "                messages=messages,\n",
    "                temperature=CONFIG[\"TEMPERATURE\"],\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            last_text, last_finish = text, finish_reason\n",
    "\n",
    "            if finish_reason == \"length\":\n",
    "                raise ValueError(\"finish_reason=length (likely truncated JSON)\")\n",
    "\n",
    "            obj = strict_parse_json(text)\n",
    "            validate_result(obj)\n",
    "            return obj\n",
    "\n",
    "        except TemporaryAPIError as e:\n",
    "            last_err = e\n",
    "            # Retry-After ä¼˜å…ˆ\n",
    "            if e.retry_after is not None and e.retry_after > 0:\n",
    "                time.sleep(min(CONFIG[\"MAX_BACKOFF_SECONDS\"], e.retry_after))\n",
    "            else:\n",
    "                _sleep_with_backoff(attempt, base=1.0, cap=CONFIG[\"MAX_BACKOFF_SECONDS\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "            # è§£æå¤±è´¥/ç–‘ä¼¼æˆªæ–­ï¼šåŠ  tokensï¼›åˆ°é¡¶åå‡è¾“å‡ºæ¡æ•°\n",
    "            likely_trunc = (\n",
    "                \"finish_reason=length\" in str(e)\n",
    "                or (last_text is not None and not clean_text(last_text).strip().endswith(\"}\"))\n",
    "            )\n",
    "\n",
    "            if likely_trunc:\n",
    "                if max_tokens < CONFIG[\"MAX_TOKENS_MAX\"]:\n",
    "                    max_tokens = min(CONFIG[\"MAX_TOKENS_MAX\"], int(max_tokens * 1.4) + 200)\n",
    "                else:\n",
    "                    if max_each_side > CONFIG[\"MIN_ITEMS_EACH_SIDE\"]:\n",
    "                        max_each_side = max(CONFIG[\"MIN_ITEMS_EACH_SIDE\"], max_each_side - 2)\n",
    "                    if max_ignored > CONFIG[\"MIN_IGNORED\"]:\n",
    "                        max_ignored = max(CONFIG[\"MIN_IGNORED\"], max_ignored - 3)\n",
    "\n",
    "            time.sleep(CONFIG[\"BASE_RETRY_SLEEP_SECONDS\"])\n",
    "\n",
    "    if CONFIG.get(\"DEBUG_SHOW_RAW_ON_FAIL\") and last_text:\n",
    "        print(\"\\n[DEBUG] Provider:\", CONFIG[\"PROVIDER\"])\n",
    "        print(\"[DEBUG] Last finish_reason:\", last_finish)\n",
    "        print(\"[DEBUG] Last model output (first 1200 chars):\")\n",
    "        print(clean_text(last_text)[:1200])\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Failed to obtain valid JSON after {CONFIG['MAX_RETRIES']} attempts. Last error: {last_err}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) DataFrame + å±•ç¤º\n",
    "# =========================\n",
    "def to_df(lst: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    if not lst:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(lst).copy()\n",
    "    if \"industries\" in df.columns:\n",
    "        df[\"industries\"] = df[\"industries\"].apply(lambda x: \"ï¼Œ\".join(x) if isinstance(x, list) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_df(df: pd.DataFrame):\n",
    "    if display is not None:\n",
    "        display(df)\n",
    "    else:\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) å¼¹å‡ºçª—å£å±•ç¤ºï¼ˆæµè§ˆå™¨æ‰“å¼€æœ¬åœ° HTMLï¼‰\n",
    "# =========================\n",
    "def popup_show_dfs(bullish_df: pd.DataFrame, bearish_df: pd.DataFrame, title: str, output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def _df_to_html(df: pd.DataFrame) -> str:\n",
    "        if df is None or df.empty:\n",
    "            return \"<p><em>ï¼ˆæ— æ•°æ®ï¼‰</em></p>\"\n",
    "        return df.to_html(index=False, escape=True)\n",
    "\n",
    "    html = f\"\"\"\n",
    "<!doctype html>\n",
    "<html lang=\"zh\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>{title}</title>\n",
    "<style>\n",
    "body {{ font-family: -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Arial; margin: 20px; }}\n",
    "h1 {{ margin-bottom: 12px; }}\n",
    "h2 {{ margin-top: 22px; }}\n",
    "table {{ border-collapse: collapse; width: 100%; }}\n",
    "th, td {{ border: 1px solid #ddd; padding: 8px; vertical-align: top; }}\n",
    "th {{ background: #f6f6f6; }}\n",
    "tr:nth-child(even) {{ background: #fafafa; }}\n",
    ".small {{ color: #666; font-size: 12px; }}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>{title}</h1>\n",
    "<div class=\"small\">ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</div>\n",
    "\n",
    "<h2>ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰</h2>\n",
    "{_df_to_html(bullish_df)}\n",
    "\n",
    "<h2>ğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰</h2>\n",
    "{_df_to_html(bearish_df)}\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\".strip()\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = os.path.abspath(os.path.join(output_dir, f\"popup_{ts}.html\"))\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    webbrowser.open(f\"file://{filepath}\", new=1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8) ä¿å­˜ Excelï¼ˆåŒä¸€æ–‡ä»¶ä¸¤å¼  sheetï¼‰\n",
    "# =========================\n",
    "def save_dfs_to_excel(bullish_df: pd.DataFrame, bearish_df: pd.DataFrame, ts_str: str, output_dir: str) -> str:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    base_name = f\"hotsearch_{ts_str}.xlsx\"\n",
    "    path = os.path.join(output_dir, base_name)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        i = 1\n",
    "        while True:\n",
    "            alt = os.path.join(output_dir, f\"hotsearch_{ts_str}_{i}.xlsx\")\n",
    "            if not os.path.exists(alt):\n",
    "                path = alt\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as writer:\n",
    "        (bullish_df if bullish_df is not None else pd.DataFrame()).to_excel(writer, sheet_name=\"åˆ©å¤š\", index=False)\n",
    "        (bearish_df if bearish_df is not None else pd.DataFrame()).to_excel(writer, sheet_name=\"åˆ©ç©º\", index=False)\n",
    "\n",
    "    return os.path.abspath(path)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 9) è¿è¡Œä¸€æ¬¡\n",
    "# =========================\n",
    "def run_once() -> Dict[str, Any]:\n",
    "    items = fetch_toutiao_hot(CONFIG[\"TOP_K\"], CONFIG[\"TOUTIAO_TIMEOUT\"])\n",
    "    result = analyze_with_retries(items)\n",
    "\n",
    "    ts_display = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    ts_fname = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    bullish_df = to_df(result.get(\"bullish\", []))\n",
    "    bearish_df = to_df(result.get(\"bearish\", []))\n",
    "\n",
    "    print(f\"\\n===== Run @ {ts_display} =====\")\n",
    "    print(f\"Provider={CONFIG['PROVIDER']} | Fetched {len(items)} hot topics. \"\n",
    "          f\"Model returned {len(result.get('bullish', []))} bullish / {len(result.get('bearish', []))} bearish.\\n\")\n",
    "\n",
    "    print(\"ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰\")\n",
    "    show_df(bullish_df)\n",
    "\n",
    "    print(\"\\nğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰\")\n",
    "    show_df(bearish_df)\n",
    "\n",
    "    if CONFIG.get(\"ENABLE_SAVE_EXCEL\"):\n",
    "        saved_path = save_dfs_to_excel(\n",
    "            bullish_df=bullish_df,\n",
    "            bearish_df=bearish_df,\n",
    "            ts_str=ts_fname,\n",
    "            output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
    "        )\n",
    "        print(f\"\\nğŸ’¾ å·²ä¿å­˜ Excelï¼š{saved_path}\")\n",
    "\n",
    "    if CONFIG.get(\"ENABLE_POPUP\"):\n",
    "        title = f\"{CONFIG.get('POPUP_TITLE_PREFIX', 'çƒ­æœåˆ†æ')} - {ts_display} ({CONFIG['PROVIDER']})\"\n",
    "        popup_show_dfs(bullish_df, bearish_df, title=title, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 10) å®šæ—¶å¾ªç¯ï¼ˆå¯é€‰ï¼‰\n",
    "# =========================\n",
    "def run_scheduler():\n",
    "    interval_sec = int(CONFIG[\"INTERVAL_MINUTES\"] * 60)\n",
    "    print(f\"Scheduler started. Provider={CONFIG['PROVIDER']}. Interval={CONFIG['INTERVAL_MINUTES']} minutes. Stop with Kernel Interrupt (â›”).\")\n",
    "    while True:\n",
    "        try:\n",
    "            run_once()\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {e}\")\n",
    "        time.sleep(interval_sec)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 11) æ‰§è¡Œå…¥å£\n",
    "# =========================\n",
    "_ = run_once()\n",
    "\n",
    "if CONFIG[\"ENABLE_SCHEDULER\"]:\n",
    "    run_scheduler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89538b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb08cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d5789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d2ca6e2",
   "metadata": {},
   "source": [
    "# åªä½¿ç”¨deepseekçš„ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4ac15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Run @ 2025-12-29 09:15:25 =====\n",
      "Fetched 30 hot topics. Model returned 3 bullish / 4 bearish.\n",
      "\n",
      "ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic</th>\n",
       "      <th>industries</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>ç‚¹ç‡ƒå†¬å­£æ–‡æ—…æ¶ˆè´¹æ–°çƒ­æ½®</td>\n",
       "      <td>æ—…æ¸¸ï¼Œæ–‡åŒ–å¨±ä¹</td>\n",
       "      <td>æ”¿ç­–æˆ–æ´»åŠ¨åˆºæ¿€æ¶ˆè´¹éœ€æ±‚ï¼Œåˆ©å¥½ç›¸å…³è¡Œä¸š</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>æ·±åœ³ä¸€è±ªå®…æ¥¼ç›˜2å°æ—¶é”€å”®è¶…100äº¿å…ƒ</td>\n",
       "      <td>æˆ¿åœ°äº§</td>\n",
       "      <td>è±ªå®…çƒ­é”€å¯èƒ½ææŒ¯å¸‚åœºä¿¡å¿ƒï¼Œåˆ©å¥½æˆ¿åœ°äº§æ¿å—</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>æ¹˜è¶…å† å†›æ°¸å·å†è¿300ä¸‡æèµ </td>\n",
       "      <td>ä½“è‚²</td>\n",
       "      <td>æèµ å¯èƒ½æ”¯æŒä½“è‚²äº§ä¸šå‘å±•ï¼Œåˆ©å¥½ä½“è‚²ç›¸å…³</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank               topic industries             mechanism  confidence\n",
       "0     3         ç‚¹ç‡ƒå†¬å­£æ–‡æ—…æ¶ˆè´¹æ–°çƒ­æ½®    æ—…æ¸¸ï¼Œæ–‡åŒ–å¨±ä¹    æ”¿ç­–æˆ–æ´»åŠ¨åˆºæ¿€æ¶ˆè´¹éœ€æ±‚ï¼Œåˆ©å¥½ç›¸å…³è¡Œä¸š         0.7\n",
       "1     9  æ·±åœ³ä¸€è±ªå®…æ¥¼ç›˜2å°æ—¶é”€å”®è¶…100äº¿å…ƒ        æˆ¿åœ°äº§  è±ªå®…çƒ­é”€å¯èƒ½ææŒ¯å¸‚åœºä¿¡å¿ƒï¼Œåˆ©å¥½æˆ¿åœ°äº§æ¿å—         0.6\n",
       "2    25      æ¹˜è¶…å† å†›æ°¸å·å†è¿300ä¸‡æèµ          ä½“è‚²   æèµ å¯èƒ½æ”¯æŒä½“è‚²äº§ä¸šå‘å±•ï¼Œåˆ©å¥½ä½“è‚²ç›¸å…³         0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic</th>\n",
       "      <th>industries</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ä¸œéƒ¨æˆ˜åŒºå†›æ¼” èˆ°æœºå¤šå‘æŠµè¿‘å°å²›</td>\n",
       "      <td>å›½é˜²å†›å·¥</td>\n",
       "      <td>åœ°ç¼˜æ”¿æ²»ç´§å¼ å¯èƒ½å¼•å‘å¸‚åœºé¿é™©æƒ…ç»ªï¼Œåˆ©ç©º</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>å›´å²›é“¾æ¡è¶Šå‹’è¶Šç´§ è§£æ”¾å†›æ¼”ä¹ åŒºå…¬å¸ƒ</td>\n",
       "      <td>å›½é˜²å†›å·¥</td>\n",
       "      <td>å†›äº‹æ¼”ä¹ åŠ å‰§ä¸ç¡®å®šæ€§ï¼Œå¯èƒ½å½±å“ç›¸å…³æ¿å—</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>æ¹–åŒ—å¤©é—¨é€šæŠ¥ä¸€èµ·è½¦è¾†è½æ°´äº‹ä»¶</td>\n",
       "      <td>æ±½è½¦ï¼Œä¿é™©</td>\n",
       "      <td>å®‰å…¨äº‹æ•…å¯èƒ½å¼•å‘ç›‘ç®¡å…³æ³¨ï¼Œåˆ©ç©ºç›¸å…³è¡Œä¸š</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>åˆ‘é‡Šäººå‘˜å½“ä¸Šå›½ä¼é«˜ç®¡ é—®é¢˜å‡ºåœ¨å“ª</td>\n",
       "      <td>å›½ä¼æ”¹é©</td>\n",
       "      <td>è´Ÿé¢æ–°é—»å¯èƒ½å½±å“å›½ä¼å½¢è±¡å’ŒæŠ•èµ„è€…ä¿¡å¿ƒ</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank              topic industries            mechanism  confidence\n",
       "0     1    ä¸œéƒ¨æˆ˜åŒºå†›æ¼” èˆ°æœºå¤šå‘æŠµè¿‘å°å²›       å›½é˜²å†›å·¥  åœ°ç¼˜æ”¿æ²»ç´§å¼ å¯èƒ½å¼•å‘å¸‚åœºé¿é™©æƒ…ç»ªï¼Œåˆ©ç©º         0.8\n",
       "1     4  å›´å²›é“¾æ¡è¶Šå‹’è¶Šç´§ è§£æ”¾å†›æ¼”ä¹ åŒºå…¬å¸ƒ       å›½é˜²å†›å·¥  å†›äº‹æ¼”ä¹ åŠ å‰§ä¸ç¡®å®šæ€§ï¼Œå¯èƒ½å½±å“ç›¸å…³æ¿å—         0.7\n",
       "2     5     æ¹–åŒ—å¤©é—¨é€šæŠ¥ä¸€èµ·è½¦è¾†è½æ°´äº‹ä»¶      æ±½è½¦ï¼Œä¿é™©  å®‰å…¨äº‹æ•…å¯èƒ½å¼•å‘ç›‘ç®¡å…³æ³¨ï¼Œåˆ©ç©ºç›¸å…³è¡Œä¸š         0.4\n",
       "3    26   åˆ‘é‡Šäººå‘˜å½“ä¸Šå›½ä¼é«˜ç®¡ é—®é¢˜å‡ºåœ¨å“ª       å›½ä¼æ”¹é©   è´Ÿé¢æ–°é—»å¯èƒ½å½±å“å›½ä¼å½¢è±¡å’ŒæŠ•èµ„è€…ä¿¡å¿ƒ         0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ å·²ä¿å­˜ Excelï¼š/Users/pz/VScode/Stock_Ana/hotsearch_stock_outputs/hotsearch_20251229_091525.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ä»Šæ—¥å¤´æ¡çƒ­æ¦œ -> DeepSeek(JSON mode)åˆ†æ -> åˆ©å¤š/åˆ©ç©ºå±•ç¤º\n",
    "# ç¨³å®šç‰ˆï¼ˆè§£å†³ï¼šæˆªæ–­/ä¸­æ–‡å¼•å·è¢«è¯¯æ›¿æ¢/å¶å‘ç©ºcontent/çœŸæ­£é‡è¯•ï¼‰\n",
    "# æ–°å¢/ä¿ç•™ï¼š\n",
    "#  1) JSON-only + æœ¬åœ°ä¸¥æ ¼æ ¡éªŒ + è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤šNæ¬¡ï¼‰\n",
    "#  2) å¯é€‰å¼¹å‡ºçª—å£ï¼ˆæµè§ˆå™¨æ‰“å¼€æœ¬åœ° HTML å±•ç¤ºä¸¤ä¸ª DFï¼‰\n",
    "#  3) æ¯æ¬¡è¿è¡Œä¿å­˜ Excelï¼ˆåŒä¸€æ–‡ä»¶ä¸¤å¼  sheetï¼šåˆ©å¤š/åˆ©ç©ºï¼›æ–‡ä»¶å=æ—¶é—´æˆ³é¿å…é‡å¤ï¼‰\n",
    "#  4) DataFrame æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼ˆå…¨éƒ¨è¡Œåˆ—+å®Œæ•´å­—ç¬¦ä¸²ï¼‰\n",
    "# ==========================================\n",
    "\n",
    "# =========================\n",
    "# A) å‚æ•°åŒºï¼ˆä½ ä¸»è¦æ”¹è¿™é‡Œï¼‰\n",
    "# =========================\n",
    "CONFIG = {\n",
    "    # å®šæ—¶è¿è¡Œ\n",
    "    \"ENABLE_SCHEDULER\": False,\n",
    "    \"INTERVAL_MINUTES\": 30,\n",
    "\n",
    "    # çƒ­æœæŠ“å–\n",
    "    \"TOP_K\": 30,\n",
    "    \"TOUTIAO_TIMEOUT\": 12,\n",
    "\n",
    "    # DeepSeekï¼ˆOpenAI å…¼å®¹ï¼‰\n",
    "    \"DEEPSEEK_API_KEY\": \"sk-1d213aa830694d2ba292a75d06cd5d77\",\n",
    "    \"DEEPSEEK_MODEL\": \"deepseek-chat\",\n",
    "    \"DEEPSEEK_BASE_URL\": \"https://api.deepseek.com/v1\",\n",
    "    \"DEEPSEEK_TIMEOUT\": 60,\n",
    "\n",
    "    # ç”Ÿæˆå‚æ•°ï¼šä»è¾ƒå°å¼€å§‹ï¼Œè‹¥æ£€æµ‹åˆ°æˆªæ–­ä¼šè‡ªåŠ¨æŠ¬å‡åˆ° MAX_TOKENS_MAX\n",
    "    \"TEMPERATURE\": 0.0,\n",
    "    \"MAX_TOKENS_START\": 1400,\n",
    "    \"MAX_TOKENS_MAX\": 4200,  # è¿‡å¤§å¯èƒ½è¢«æœåŠ¡ç«¯æ‹’ç»ï¼›ä¼šè‡ªåŠ¨å›é€€\n",
    "\n",
    "    # è¾“å‡ºæ§åˆ¶ï¼ˆè‹¥å¤šæ¬¡æˆªæ–­ï¼Œä¼šè‡ªåŠ¨é™ä½æ¡æ•°ï¼‰\n",
    "    \"MAX_ITEMS_EACH_SIDE\": 12,\n",
    "    \"MAX_IGNORED\": 12,\n",
    "    \"MIN_ITEMS_EACH_SIDE\": 5,\n",
    "    \"MIN_IGNORED\": 0,\n",
    "\n",
    "    # é‡è¯•æ§åˆ¶\n",
    "    \"MAX_DEEPSEEK_RETRIES\": 1,\n",
    "    \"BASE_RETRY_SLEEP_SECONDS\": 0.6,\n",
    "    \"MAX_BACKOFF_SECONDS\": 20,\n",
    "\n",
    "    # è°ƒè¯•\n",
    "    \"DEBUG_SHOW_RAW_ON_FAIL\": True,\n",
    "    \"DEBUG_SHOW_API_ERROR_TEXT\": False,\n",
    "\n",
    "    # ç»“æœå±•ç¤ºï¼šå¼¹å‡ºçª—å£\n",
    "    \"ENABLE_POPUP\": True,\n",
    "    \"POPUP_TITLE_PREFIX\": \"çƒ­æœåˆ©å¤š/åˆ©ç©ºåˆ†æ\",\n",
    "\n",
    "    # ç»“æœä¿å­˜ï¼šExcel\n",
    "    \"ENABLE_SAVE_EXCEL\": True,\n",
    "    \"OUTPUT_DIR\": \"./hotsearch_stock_outputs\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# B) ä¾èµ–\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from IPython.display import display  # type: ignore\n",
    "except Exception:\n",
    "    display = None\n",
    "\n",
    "# DataFrame æ˜¾ç¤ºï¼šå…¨éƒ¨è¡Œåˆ— + å®Œæ•´å­—ç¬¦ä¸²\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 0)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) å°å·¥å…·ï¼šæ ‡é¢˜å‡€åŒ–ï¼ˆé¿å… ASCII åŒå¼•å·ç ´å JSONï¼‰\n",
    "# =========================\n",
    "def sanitize_title_for_model(title: str) -> str:\n",
    "    \"\"\"\n",
    "    æŠŠæ ‡é¢˜é‡Œçš„ ASCII åŒå¼•å·æ›¿æ¢æˆä¸­æ–‡å¼•å·ï¼Œé¿å…æ¨¡å‹åŸæ ·æ‹·è´å¯¼è‡´ JSON å­—ç¬¦ä¸²æœªè½¬ä¹‰ã€‚\n",
    "    åŒæ—¶å»æ‰æ§åˆ¶å­—ç¬¦ï¼ˆ\\r \\t ç­‰ï¼‰ï¼Œé¿å…å‡ºç° JSON å­—ç¬¦ä¸²å†…éæ³•æ¢è¡Œã€‚\n",
    "    \"\"\"\n",
    "    if title is None:\n",
    "        return \"\"\n",
    "    s = str(title)\n",
    "\n",
    "    # ASCII \" -> ä¸­æ–‡å¼•å·ï¼ˆæˆå¯¹æ›¿æ¢å¾ˆå¤æ‚ï¼Œè¿™é‡Œç®€å•æ›¿æ¢æˆâ€œï¼‰\n",
    "    s = s.replace('\"', \"â€œ\")\n",
    "\n",
    "    # å»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™å¸¸è§„å¯è¯»å­—ç¬¦ï¼‰\n",
    "    s = re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\", \" \", s)\n",
    "    s = s.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "\n",
    "    # å‹ç¼©å¤šä½™ç©ºæ ¼\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) æŠ“å–ä»Šæ—¥å¤´æ¡çƒ­æ¦œ\n",
    "# =========================\n",
    "def fetch_toutiao_hot(top_k: int = 30, timeout: int = 12) -> List[Dict[str, Any]]:\n",
    "    url = \"https://www.toutiao.com/hot-event/hot-board/?origin=toutiao_pc\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Referer\": \"https://www.toutiao.com/\",\n",
    "        \"Accept\": \"application/json,text/plain,*/*\",\n",
    "    }\n",
    "    r = requests.get(url, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    payload = r.json()\n",
    "\n",
    "    data = payload.get(\"data\")\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Unexpected response schema. Top keys: {list(payload.keys())}\")\n",
    "\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    for i, it in enumerate(data[:top_k], start=1):\n",
    "        title = it.get(\"Title\") or it.get(\"title\") or \"\"\n",
    "        hot_value = it.get(\"HotValue\") or it.get(\"hot_value\") or 0\n",
    "        link = it.get(\"Url\") or it.get(\"url\") or \"\"\n",
    "\n",
    "        try:\n",
    "            hot_value_num = float(hot_value)\n",
    "        except Exception:\n",
    "            hot_value_num = None\n",
    "\n",
    "        items.append({\n",
    "            \"rank\": i,\n",
    "            \"title\": str(title).strip(),\n",
    "            \"hot_value\": hot_value_num,\n",
    "            \"url\": str(link).strip(),\n",
    "        })\n",
    "\n",
    "    return [x for x in items if x[\"title\"]]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) DeepSeek è°ƒç”¨ï¼ˆOpenAI å…¼å®¹ chat/completionsï¼‰\n",
    "# =========================\n",
    "class TemporaryAPIError(Exception):\n",
    "    def __init__(self, msg: str, status_code: Optional[int] = None, retry_after: Optional[float] = None):\n",
    "        super().__init__(msg)\n",
    "        self.status_code = status_code\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "\n",
    "def deepseek_chat_raw(\n",
    "    api_key: str,\n",
    "    base_url: str,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    timeout: int,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    ") -> Tuple[str, Dict[str, Any], Optional[str]]:\n",
    "    \"\"\"\n",
    "    è¿”å› (content_text, raw_json, finish_reason)\n",
    "    \"\"\"\n",
    "    endpoint = base_url.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    body: Dict[str, Any] = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": False,\n",
    "        \"response_format\": {\"type\": \"json_object\"},  # JSON mode\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(endpoint, headers=headers, json=body, timeout=timeout)\n",
    "    except requests.RequestException as e:\n",
    "        raise TemporaryAPIError(f\"Network error: {e}\", status_code=None) from e\n",
    "\n",
    "    if r.status_code in (429, 500, 502, 503, 504):\n",
    "        retry_after = None\n",
    "        ra = r.headers.get(\"Retry-After\")\n",
    "        if ra:\n",
    "            try:\n",
    "                retry_after = float(ra)\n",
    "            except Exception:\n",
    "                retry_after = None\n",
    "\n",
    "        msg = f\"Temporary HTTP {r.status_code}\"\n",
    "        if CONFIG.get(\"DEBUG_SHOW_API_ERROR_TEXT\"):\n",
    "            msg += f\": {r.text[:1000]}\"\n",
    "        raise TemporaryAPIError(msg, status_code=r.status_code, retry_after=retry_after)\n",
    "\n",
    "    if not r.ok:\n",
    "        # éä¸´æ—¶é”™è¯¯ï¼šç›´æ¥æŠ›å‡º\n",
    "        raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:1500]}\")\n",
    "\n",
    "    raw = r.json()\n",
    "    choice0 = raw[\"choices\"][0]\n",
    "    finish_reason = choice0.get(\"finish_reason\")\n",
    "\n",
    "    msg = choice0[\"message\"]\n",
    "    content = msg.get(\"content\")\n",
    "\n",
    "    # JSON mode å¶å‘ç©º contentï¼šå½“ä½œå¯é‡è¯•\n",
    "    if not isinstance(content, str) or not content.strip():\n",
    "        raise TemporaryAPIError(\"Empty content returned (JSON mode).\", status_code=200)\n",
    "\n",
    "    return content, raw, finish_reason\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) JSON æ¸…ç†/è§£æ/æ ¡éªŒï¼ˆé‡è¦ï¼šä¸å†æŠŠä¸­æ–‡å¼•å·æ›¿æ¢æˆ ASCII å¼•å·ï¼‰\n",
    "# =========================\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    # å»æ‰ ```json``` åŒ…è£¹ï¼ˆä¿é™©ï¼‰\n",
    "    s = re.sub(r\"^```(?:json)?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "\n",
    "    # JSON ä¸å…è®¸ NaN/Infinity\n",
    "    s = re.sub(r\"\\bNaN\\b\", \"null\", s)\n",
    "    s = re.sub(r\"\\bInfinity\\b\", \"null\", s)\n",
    "    s = re.sub(r\"\\b-Infinity\\b\", \"null\", s)\n",
    "\n",
    "    # å°¾é€—å·ï¼ˆä¿é™©ï¼‰\n",
    "    s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def strict_parse_json(s: str) -> Dict[str, Any]:\n",
    "    s2 = clean_text(s).strip()\n",
    "    if not (s2.startswith(\"{\") and s2.endswith(\"}\")):\n",
    "        raise ValueError(\"Output is not a pure JSON object (missing { } boundaries).\")\n",
    "    obj = json.loads(s2)\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"JSON is not an object.\")\n",
    "    return obj\n",
    "\n",
    "\n",
    "def validate_result(obj: Dict[str, Any]) -> None:\n",
    "    for k in [\"bullish\", \"bearish\", \"ignored\"]:\n",
    "        if k not in obj:\n",
    "            raise ValueError(f\"Missing key: {k}\")\n",
    "        if not isinstance(obj[k], list):\n",
    "            raise ValueError(f\"Key '{k}' must be a list.\")\n",
    "\n",
    "    # è¿›ä¸€æ­¥æ ¡éªŒå­—æ®µ/èŒƒå›´ï¼ˆå°½é‡æ—©å‘ç°â€œçœ‹ä¼¼ JSON ä½†ç»“æ„ä¹±äº†â€ï¼‰\n",
    "    def _check_side(side_name: str):\n",
    "        for it in obj.get(side_name, []):\n",
    "            if not isinstance(it, dict):\n",
    "                raise ValueError(f\"{side_name} item not object.\")\n",
    "            for need in [\"rank\", \"topic\", \"industries\", \"mechanism\", \"confidence\"]:\n",
    "                if need not in it:\n",
    "                    raise ValueError(f\"{side_name} missing field: {need}\")\n",
    "            if not isinstance(it[\"industries\"], list):\n",
    "                raise ValueError(f\"{side_name}.industries must be list\")\n",
    "            c = it[\"confidence\"]\n",
    "            if not (isinstance(c, (int, float)) and 0.0 <= float(c) <= 1.0):\n",
    "                raise ValueError(f\"{side_name}.confidence out of range: {c}\")\n",
    "\n",
    "    _check_side(\"bullish\")\n",
    "    _check_side(\"bearish\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Promptï¼ˆæ›´çŸ­ã€æ›´ä¸å®¹æ˜“æˆªæ–­ï¼›å¼ºåˆ¶â€œå®å¯å°‘æ¡ç›®ä¹Ÿè¦å®Œæ•´ JSONâ€ï¼‰\n",
    "# =========================\n",
    "def build_messages(items: List[Dict[str, Any]], max_each_side: int, max_ignored: int) -> List[Dict[str, str]]:\n",
    "    hot_lines = []\n",
    "    for it in items:\n",
    "        hv = it[\"hot_value\"]\n",
    "        hv_str = f\"{hv:.0f}\" if isinstance(hv, (int, float)) and hv is not None else \"\"\n",
    "        safe_title = sanitize_title_for_model(it[\"title\"])\n",
    "        hot_lines.append(f'{it[\"rank\"]}. {safe_title} (HotValue={hv_str})')\n",
    "\n",
    "    system = (\n",
    "        \"ä½ æ˜¯ä¸¥è°¨çš„ä¸­æ–‡é‡‘èä¿¡æ¯åˆ†æåŠ©æ‰‹ã€‚\"\n",
    "        \"ä½ å¿…é¡»åªè¾“å‡ºjsonå¯¹è±¡ï¼ˆä¸¥æ ¼JSONï¼‰ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚\"\n",
    "        \"å¦‚æœä½ å‘ç°è¾“å‡ºå¯èƒ½è¿‡é•¿ï¼Œå®å¯å‡å°‘æ¡ç›®æ•°ï¼Œä¹Ÿå¿…é¡»ä¿è¯è¾“å‡ºä¸ºå®Œæ•´åˆæ³•JSONã€‚\"\n",
    "    )\n",
    "\n",
    "    user = f\"\"\"\n",
    "è¯·åŸºäºä¸‹é¢çš„â€œä»Šæ—¥å¤´æ¡çƒ­æ¦œæ ‡é¢˜åˆ—è¡¨â€ï¼ŒæŒ‘é€‰å‡ºå¯èƒ½å¼•èµ·ç›¸å…³è¡Œä¸š/æ¿å—çŸ­æœŸè‚¡ä»·æ³¢åŠ¨çš„æ ‡é¢˜ï¼Œå¹¶åˆ†ä¸ºï¼š\n",
    "- bullishï¼ˆåˆ©å¤šï¼‰\n",
    "- bearishï¼ˆåˆ©ç©ºï¼‰\n",
    "- ignoredï¼ˆä¸å¤ªç›¸å…³ï¼‰\n",
    "\n",
    "ä¸¥æ ¼è¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š\n",
    "- åªè¾“å‡ºä¸¥æ ¼jsonï¼ˆJSONå¯¹è±¡ï¼‰ï¼Œä¸è¦ markdownï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦ä»»ä½•å‰åç¼€ã€‚\n",
    "- è¾“å‡ºå¿…é¡»ä»¥ {{ å¼€å¤´ï¼Œä»¥ }} ç»“å°¾ã€‚\n",
    "- æ¯ç»„ bullish/bearish æœ€å¤š {max_each_side} æ¡ï¼›ignored æœ€å¤š {max_ignored} æ¡ã€‚\n",
    "- mechanism å¿…é¡»éå¸¸çŸ­ï¼š<= 25 ä¸ªæ±‰å­—ï¼ˆä¸è¦æ¢è¡Œï¼‰ã€‚\n",
    "- ä¸è¦ç¼–é€ å…·ä½“è‚¡ç¥¨ä»£ç ï¼›åªç»™è¡Œä¸š/æ¿å—ã€‚\n",
    "- å¦‚æœæ ‡é¢˜å«æœ‰å¼•å·ï¼Œè¯·ä½¿ç”¨ä¸­æ–‡å¼•å·ï¼ˆâ€œ â€ï¼‰æˆ–å•å¼•å·ï¼Œä¸è¦ä½¿ç”¨ASCIIåŒå¼•å·å­—ç¬¦ \" ã€‚\n",
    "\n",
    "å›ºå®š JSON Schemaï¼ˆå­—æ®µåå¿…é¡»ä¸€è‡´ï¼‰ï¼š\n",
    "{{\n",
    "  \"bullish\": [{{\"rank\": 1, \"topic\": \"...\", \"industries\": [\"...\"], \"mechanism\": \"...\", \"confidence\": 0.0}}],\n",
    "  \"bearish\":  [{{\"rank\": 1, \"topic\": \"...\", \"industries\": [\"...\"], \"mechanism\": \"...\", \"confidence\": 0.0}}],\n",
    "  \"ignored\":  [{{\"rank\": 1, \"topic\": \"...\", \"reason\": \"...\"}}]\n",
    "}}\n",
    "\n",
    "çƒ­æ¦œæ ‡é¢˜åˆ—è¡¨ï¼š\n",
    "{chr(10).join(hot_lines)}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) é‡è¯•ç­–ç•¥ï¼ˆæŒ‰å¤±è´¥åŸå› è‡ªé€‚åº”ï¼šæˆªæ–­->åŠ tokens/å‡æ¡ç›®ï¼‰\n",
    "# =========================\n",
    "def _sleep_with_backoff(attempt: int, base: float, cap: float) -> None:\n",
    "    wait = min(cap, base * (1.7 ** (attempt - 1)))\n",
    "    wait *= (0.85 + 0.3 * random.random())\n",
    "    time.sleep(wait)\n",
    "\n",
    "\n",
    "def deepseek_analyze_with_retries(items: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    last_text: Optional[str] = None\n",
    "    last_err: Optional[Exception] = None\n",
    "    last_finish: Optional[str] = None\n",
    "\n",
    "    max_tokens = int(CONFIG[\"MAX_TOKENS_START\"])\n",
    "    max_each_side = int(CONFIG[\"MAX_ITEMS_EACH_SIDE\"])\n",
    "    max_ignored = int(CONFIG[\"MAX_IGNORED\"])\n",
    "\n",
    "    for attempt in range(1, CONFIG[\"MAX_DEEPSEEK_RETRIES\"] + 1):\n",
    "        messages = build_messages(items, max_each_side=max_each_side, max_ignored=max_ignored)\n",
    "\n",
    "        try:\n",
    "            text, raw, finish_reason = deepseek_chat_raw(\n",
    "                api_key=CONFIG[\"DEEPSEEK_API_KEY\"],\n",
    "                base_url=CONFIG[\"DEEPSEEK_BASE_URL\"],\n",
    "                model=CONFIG[\"DEEPSEEK_MODEL\"],\n",
    "                messages=messages,\n",
    "                timeout=CONFIG[\"DEEPSEEK_TIMEOUT\"],\n",
    "                temperature=CONFIG[\"TEMPERATURE\"],\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            last_text, last_finish = text, finish_reason\n",
    "\n",
    "            # è‹¥ finish_reason=lengthï¼Œå®˜æ–¹è¯´æ˜å¯èƒ½è¢«æˆªæ–­ï¼šç›´æ¥èµ°â€œåŠ tokens/å‡æ¡ç›®â€é‡è¯•é€»è¾‘\n",
    "            if finish_reason == \"length\":\n",
    "                raise ValueError(\"finish_reason=length (likely truncated JSON)\")\n",
    "\n",
    "            obj = strict_parse_json(text)\n",
    "            validate_result(obj)\n",
    "            return obj\n",
    "\n",
    "        except TemporaryAPIError as e:\n",
    "            last_err = e\n",
    "            # Retry-After ä¼˜å…ˆï¼Œå¦åˆ™æŒ‡æ•°é€€é¿\n",
    "            if e.retry_after is not None and e.retry_after > 0:\n",
    "                time.sleep(min(CONFIG[\"MAX_BACKOFF_SECONDS\"], e.retry_after))\n",
    "            else:\n",
    "                _sleep_with_backoff(attempt, base=1.0, cap=CONFIG[\"MAX_BACKOFF_SECONDS\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "            # â€”â€” è§£æå¤±è´¥/ç–‘ä¼¼æˆªæ–­ï¼šä¼˜å…ˆåŠ  max_tokensï¼›åˆ°ä¸Šé™åå†å‡è¾“å‡ºæ¡æ•°\n",
    "            msg = str(e)\n",
    "\n",
    "            # ç»éªŒåˆ¤æ–­ï¼šç¼ºå³æ‹¬å·/æˆªæ–­/finish_reason length\n",
    "            likely_trunc = (\"truncated\" in msg.lower()) or (\"finish_reason=length\" in msg) or (\n",
    "                last_text is not None and not clean_text(last_text).strip().endswith(\"}\")\n",
    "            )\n",
    "\n",
    "            if likely_trunc:\n",
    "                if max_tokens < CONFIG[\"MAX_TOKENS_MAX\"]:\n",
    "                    max_tokens = min(CONFIG[\"MAX_TOKENS_MAX\"], int(max_tokens * 1.4) + 200)\n",
    "                else:\n",
    "                    # tokens å·²åˆ°é¡¶ï¼šå‡æ¡ç›®æ•°ï¼Œä¿è¯èƒ½å®Œæ•´è¾“å‡º\n",
    "                    if max_each_side > CONFIG[\"MIN_ITEMS_EACH_SIDE\"]:\n",
    "                        max_each_side = max(CONFIG[\"MIN_ITEMS_EACH_SIDE\"], max_each_side - 2)\n",
    "                    if max_ignored > CONFIG[\"MIN_IGNORED\"]:\n",
    "                        max_ignored = max(CONFIG[\"MIN_IGNORED\"], max_ignored - 3)\n",
    "            time.sleep(CONFIG[\"BASE_RETRY_SLEEP_SECONDS\"])\n",
    "\n",
    "    if CONFIG.get(\"DEBUG_SHOW_RAW_ON_FAIL\") and last_text:\n",
    "        print(\"\\n[DEBUG] Last finish_reason:\", last_finish)\n",
    "        print(\"[DEBUG] Last model output (first 1200 chars):\")\n",
    "        print(clean_text(last_text)[:1200])\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Failed to obtain valid JSON after {CONFIG['MAX_DEEPSEEK_RETRIES']} attempts. \"\n",
    "        f\"Last error: {last_err}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) DataFrame + å±•ç¤º\n",
    "# =========================\n",
    "def to_df(lst: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    if not lst:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(lst).copy()\n",
    "    if \"industries\" in df.columns:\n",
    "        df[\"industries\"] = df[\"industries\"].apply(lambda x: \"ï¼Œ\".join(x) if isinstance(x, list) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_df(df: pd.DataFrame):\n",
    "    if display is not None:\n",
    "        display(df)\n",
    "    else:\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) å¼¹å‡ºçª—å£å±•ç¤ºï¼ˆæµè§ˆå™¨æ‰“å¼€æœ¬åœ° HTMLï¼‰\n",
    "# =========================\n",
    "def popup_show_dfs(bullish_df: pd.DataFrame, bearish_df: pd.DataFrame, title: str, output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def _df_to_html(df: pd.DataFrame) -> str:\n",
    "        if df is None or df.empty:\n",
    "            return \"<p><em>ï¼ˆæ— æ•°æ®ï¼‰</em></p>\"\n",
    "        return df.to_html(index=False, escape=True)\n",
    "\n",
    "    html = f\"\"\"\n",
    "<!doctype html>\n",
    "<html lang=\"zh\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>{title}</title>\n",
    "<style>\n",
    "body {{ font-family: -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Arial; margin: 20px; }}\n",
    "h1 {{ margin-bottom: 12px; }}\n",
    "h2 {{ margin-top: 22px; }}\n",
    "table {{ border-collapse: collapse; width: 100%; }}\n",
    "th, td {{ border: 1px solid #ddd; padding: 8px; vertical-align: top; }}\n",
    "th {{ background: #f6f6f6; }}\n",
    "tr:nth-child(even) {{ background: #fafafa; }}\n",
    ".small {{ color: #666; font-size: 12px; }}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>{title}</h1>\n",
    "<div class=\"small\">ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</div>\n",
    "\n",
    "<h2>ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰</h2>\n",
    "{_df_to_html(bullish_df)}\n",
    "\n",
    "<h2>ğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰</h2>\n",
    "{_df_to_html(bearish_df)}\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\".strip()\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = os.path.abspath(os.path.join(output_dir, f\"popup_{ts}.html\"))\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    webbrowser.open(f\"file://{filepath}\", new=1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8) ä¿å­˜ Excelï¼ˆåŒä¸€æ–‡ä»¶ä¸¤å¼  sheetï¼‰\n",
    "# =========================\n",
    "def save_dfs_to_excel(bullish_df: pd.DataFrame, bearish_df: pd.DataFrame, ts_str: str, output_dir: str) -> str:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    base_name = f\"hotsearch_{ts_str}.xlsx\"\n",
    "    path = os.path.join(output_dir, base_name)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        i = 1\n",
    "        while True:\n",
    "            alt = os.path.join(output_dir, f\"hotsearch_{ts_str}_{i}.xlsx\")\n",
    "            if not os.path.exists(alt):\n",
    "                path = alt\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as writer:\n",
    "        (bullish_df if bullish_df is not None else pd.DataFrame()).to_excel(writer, sheet_name=\"åˆ©å¤š\", index=False)\n",
    "        (bearish_df if bearish_df is not None else pd.DataFrame()).to_excel(writer, sheet_name=\"åˆ©ç©º\", index=False)\n",
    "\n",
    "    return os.path.abspath(path)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 9) è¿è¡Œä¸€æ¬¡\n",
    "# =========================\n",
    "def run_once() -> Dict[str, Any]:\n",
    "    items = fetch_toutiao_hot(CONFIG[\"TOP_K\"], CONFIG[\"TOUTIAO_TIMEOUT\"])\n",
    "    result = deepseek_analyze_with_retries(items)\n",
    "\n",
    "    ts_display = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    ts_fname = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    bullish_df = to_df(result.get(\"bullish\", []))\n",
    "    bearish_df = to_df(result.get(\"bearish\", []))\n",
    "\n",
    "    print(f\"\\n===== Run @ {ts_display} =====\")\n",
    "    print(f\"Fetched {len(items)} hot topics. \"\n",
    "          f\"Model returned {len(result.get('bullish', []))} bullish / {len(result.get('bearish', []))} bearish.\\n\")\n",
    "\n",
    "    print(\"ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰\")\n",
    "    show_df(bullish_df)\n",
    "\n",
    "    print(\"\\nğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰\")\n",
    "    show_df(bearish_df)\n",
    "\n",
    "    if CONFIG.get(\"ENABLE_SAVE_EXCEL\"):\n",
    "        saved_path = save_dfs_to_excel(\n",
    "            bullish_df=bullish_df,\n",
    "            bearish_df=bearish_df,\n",
    "            ts_str=ts_fname,\n",
    "            output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
    "        )\n",
    "        print(f\"\\nğŸ’¾ å·²ä¿å­˜ Excelï¼š{saved_path}\")\n",
    "\n",
    "    if CONFIG.get(\"ENABLE_POPUP\"):\n",
    "        title = f\"{CONFIG.get('POPUP_TITLE_PREFIX', 'çƒ­æœåˆ†æ')} - {ts_display}\"\n",
    "        popup_show_dfs(bullish_df, bearish_df, title=title, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 10) å®šæ—¶å¾ªç¯ï¼ˆå¯é€‰ï¼‰\n",
    "# =========================\n",
    "def run_scheduler():\n",
    "    interval_sec = int(CONFIG[\"INTERVAL_MINUTES\"] * 60)\n",
    "    print(f\"Scheduler started. Interval={CONFIG['INTERVAL_MINUTES']} minutes. Stop with Kernel Interrupt (â›”).\")\n",
    "    while True:\n",
    "        try:\n",
    "            run_once()\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {e}\")\n",
    "        time.sleep(interval_sec)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 11) æ‰§è¡Œå…¥å£\n",
    "# =========================\n",
    "_ = run_once()\n",
    "\n",
    "if CONFIG[\"ENABLE_SCHEDULER\"]:\n",
    "    run_scheduler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacb143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "909af450",
   "metadata": {},
   "source": [
    "# åªä½¿ç”¨qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0974ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Run @ 2025-12-29 08:53:27 =====\n",
      "Fetched 30 hot topics. Model returned 2 bullish / 4 bearish.\n",
      "\n",
      "ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic</th>\n",
       "      <th>industries</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>æ·±åœ³ä¸€è±ªå®…æ¥¼ç›˜2å°æ—¶é”€å”®è¶…100äº¿å…ƒ</td>\n",
       "      <td>æˆ¿åœ°äº§ï¼Œé«˜ç«¯ä½å®…ï¼Œå»ºç­‘ææ–™</td>\n",
       "      <td>ä¸€çº¿åŸå¸‚é«˜ç«¯æ¥¼å¸‚é”€å”®å›æš–ï¼Œå¯èƒ½é¢„ç¤ºåœ°äº§æ”¿ç­–æ”¾æ¾æ•ˆæœæ˜¾ç°ï¼Œå¸¦åŠ¨å¸‚åœºå¯¹æˆ¿åœ°äº§æ¿å—ä¿¡å¿ƒä¿®å¤ï¼Œå°¤å…¶åˆ©å¥½å¤´éƒ¨æˆ¿ä¼åŠå»ºæä¾›åº”é“¾</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>ç‚¹ç‡ƒå†¬å­£æ–‡æ—…æ¶ˆè´¹æ–°çƒ­æ½®</td>\n",
       "      <td>æ—…æ¸¸ï¼Œé…’åº—é¤é¥®ï¼Œæ–‡åŒ–å¨±ä¹</td>\n",
       "      <td>æ”¿ç­–æˆ–æ´»åŠ¨æ¨åŠ¨å†¬å­£æ–‡æ—…æ¶ˆè´¹ï¼ŒçŸ­æœŸå†…æå‡å‡ºè¡ŒåŠæœåŠ¡ç±»æ¶ˆè´¹éœ€æ±‚ï¼Œåˆ©å¥½æ™¯åŒºã€OTAå¹³å°åŠè¿é”é¤é¥®ä¼ä¸š</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank               topic     industries                                                  mechanism  confidence\n",
       "0     7  æ·±åœ³ä¸€è±ªå®…æ¥¼ç›˜2å°æ—¶é”€å”®è¶…100äº¿å…ƒ  æˆ¿åœ°äº§ï¼Œé«˜ç«¯ä½å®…ï¼Œå»ºç­‘ææ–™  ä¸€çº¿åŸå¸‚é«˜ç«¯æ¥¼å¸‚é”€å”®å›æš–ï¼Œå¯èƒ½é¢„ç¤ºåœ°äº§æ”¿ç­–æ”¾æ¾æ•ˆæœæ˜¾ç°ï¼Œå¸¦åŠ¨å¸‚åœºå¯¹æˆ¿åœ°äº§æ¿å—ä¿¡å¿ƒä¿®å¤ï¼Œå°¤å…¶åˆ©å¥½å¤´éƒ¨æˆ¿ä¼åŠå»ºæä¾›åº”é“¾        0.85\n",
       "1     3         ç‚¹ç‡ƒå†¬å­£æ–‡æ—…æ¶ˆè´¹æ–°çƒ­æ½®   æ—…æ¸¸ï¼Œé…’åº—é¤é¥®ï¼Œæ–‡åŒ–å¨±ä¹            æ”¿ç­–æˆ–æ´»åŠ¨æ¨åŠ¨å†¬å­£æ–‡æ—…æ¶ˆè´¹ï¼ŒçŸ­æœŸå†…æå‡å‡ºè¡ŒåŠæœåŠ¡ç±»æ¶ˆè´¹éœ€æ±‚ï¼Œåˆ©å¥½æ™¯åŒºã€OTAå¹³å°åŠè¿é”é¤é¥®ä¼ä¸š        0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic</th>\n",
       "      <th>industries</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ä¸œéƒ¨æˆ˜åŒºå†›æ¼” èˆ°æœºå¤šå‘æŠµè¿‘å°å²›</td>\n",
       "      <td>åŠå¯¼ä½“ï¼Œç”µå­åˆ¶é€ ï¼Œèˆªè¿ç‰©æµ</td>\n",
       "      <td>åœ°ç¼˜æ”¿æ²»ç´§å¼ å‡çº§å¯èƒ½å¯¼è‡´å°æµ·ä¾›åº”é“¾æ‰°åŠ¨é¢„æœŸï¼Œå¸‚åœºæ‹…å¿§ä¸¤å²¸äº¤æµä¸­æ–­å½±å“èŠ¯ç‰‡ç­‰äº§ä¸šä¸Šä¸‹æ¸¸åä½œï¼Œå¼•å‘ç›¸å…³ç§‘æŠ€ä¸è¿è¾“æ¿å—çŸ­æœŸé¿é™©æƒ…ç»ª</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>å›´å²›æ¼”ä¹ ï¼ä¸œéƒ¨æˆ˜åŒºå‘å¸ƒæ¼”è®­ç¤ºæ„å›¾</td>\n",
       "      <td>åŠå¯¼ä½“ï¼Œç”µå­åˆ¶é€ ï¼Œèˆªè¿ç‰©æµ</td>\n",
       "      <td>è¿›ä¸€æ­¥å¼ºåŒ–å†›äº‹è¡ŒåŠ¨å¯è§†åŒ–ï¼ŒåŠ å‰§å¸‚åœºå¯¹å°æµ·å±€åŠ¿å¤±æ§çš„æ‹…å¿§ï¼Œæ”¾å¤§å…¨çƒä¾›åº”é“¾ä¸­æ–­é£é™©é¢„æœŸï¼Œå‹åˆ¶å‡ºå£å¯¼å‘å‹ç§‘æŠ€ä¸èˆªè¿æ¿å—ä¼°å€¼</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>å¤§èŒƒå›´é›¨é›ªæ¥äº† å…ƒæ—¦å¤§é™æ¸©è¶‹åŠ¿ç¡®å®š</td>\n",
       "      <td>å†œä¸šï¼Œäº¤é€šè¿è¾“ï¼Œé›¶å”®</td>\n",
       "      <td>æç«¯å¤©æ°”å°†å½±å“å†œäº§å“è¿è¾“ä¸ä¾›åº”ï¼Œæ¨é«˜ç”Ÿé²œæŸè€—ç‡ï¼ŒåŒæ—¶æŠ‘åˆ¶èŠ‚å‰æ¶ˆè´¹å‡ºè¡Œï¼Œå¯¹å†œä¸šä¾›åº”é“¾å’Œçº¿ä¸‹é›¶å”®å½¢æˆçŸ­æœŸå‹åŠ›</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>å†·ç©ºæ°”ä¼´æˆ‘ä»¬è·¨å¹´</td>\n",
       "      <td>å†œä¸šï¼Œäº¤é€šè¿è¾“</td>\n",
       "      <td>æŒç»­ä½æ¸©å¤©æ°”å»¶é•¿ç‰©æµä¸­æ–­æ—¶é—´ï¼Œå¢åŠ å†·é“¾ä¸é…é€æˆæœ¬ï¼Œè¿›ä¸€æ­¥å†²å‡»ç”Ÿé²œä¾›åº”ç¨³å®šæ€§ï¼Œæ‹–ç´¯å†œä¸šä¸è¿è¾“æ¿å—è¡¨ç°</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank              topic     industries                                                       mechanism  confidence\n",
       "0     1    ä¸œéƒ¨æˆ˜åŒºå†›æ¼” èˆ°æœºå¤šå‘æŠµè¿‘å°å²›  åŠå¯¼ä½“ï¼Œç”µå­åˆ¶é€ ï¼Œèˆªè¿ç‰©æµ  åœ°ç¼˜æ”¿æ²»ç´§å¼ å‡çº§å¯èƒ½å¯¼è‡´å°æµ·ä¾›åº”é“¾æ‰°åŠ¨é¢„æœŸï¼Œå¸‚åœºæ‹…å¿§ä¸¤å²¸äº¤æµä¸­æ–­å½±å“èŠ¯ç‰‡ç­‰äº§ä¸šä¸Šä¸‹æ¸¸åä½œï¼Œå¼•å‘ç›¸å…³ç§‘æŠ€ä¸è¿è¾“æ¿å—çŸ­æœŸé¿é™©æƒ…ç»ª        0.90\n",
       "1     4   å›´å²›æ¼”ä¹ ï¼ä¸œéƒ¨æˆ˜åŒºå‘å¸ƒæ¼”è®­ç¤ºæ„å›¾  åŠå¯¼ä½“ï¼Œç”µå­åˆ¶é€ ï¼Œèˆªè¿ç‰©æµ      è¿›ä¸€æ­¥å¼ºåŒ–å†›äº‹è¡ŒåŠ¨å¯è§†åŒ–ï¼ŒåŠ å‰§å¸‚åœºå¯¹å°æµ·å±€åŠ¿å¤±æ§çš„æ‹…å¿§ï¼Œæ”¾å¤§å…¨çƒä¾›åº”é“¾ä¸­æ–­é£é™©é¢„æœŸï¼Œå‹åˆ¶å‡ºå£å¯¼å‘å‹ç§‘æŠ€ä¸èˆªè¿æ¿å—ä¼°å€¼        0.88\n",
       "2    24  å¤§èŒƒå›´é›¨é›ªæ¥äº† å…ƒæ—¦å¤§é™æ¸©è¶‹åŠ¿ç¡®å®š     å†œä¸šï¼Œäº¤é€šè¿è¾“ï¼Œé›¶å”®            æç«¯å¤©æ°”å°†å½±å“å†œäº§å“è¿è¾“ä¸ä¾›åº”ï¼Œæ¨é«˜ç”Ÿé²œæŸè€—ç‡ï¼ŒåŒæ—¶æŠ‘åˆ¶èŠ‚å‰æ¶ˆè´¹å‡ºè¡Œï¼Œå¯¹å†œä¸šä¾›åº”é“¾å’Œçº¿ä¸‹é›¶å”®å½¢æˆçŸ­æœŸå‹åŠ›        0.70\n",
       "3    29           å†·ç©ºæ°”ä¼´æˆ‘ä»¬è·¨å¹´        å†œä¸šï¼Œäº¤é€šè¿è¾“               æŒç»­ä½æ¸©å¤©æ°”å»¶é•¿ç‰©æµä¸­æ–­æ—¶é—´ï¼Œå¢åŠ å†·é“¾ä¸é…é€æˆæœ¬ï¼Œè¿›ä¸€æ­¥å†²å‡»ç”Ÿé²œä¾›åº”ç¨³å®šæ€§ï¼Œæ‹–ç´¯å†œä¸šä¸è¿è¾“æ¿å—è¡¨ç°        0.65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ å·²ä¿å­˜ Excelï¼š/Users/pz/VScode/Stock_Ana/hotsearch_stock_outputs/hotsearch_20251229_085327.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ä»Šæ—¥å¤´æ¡çƒ­æ¦œ -> åƒé—®åˆ†æ -> åˆ©å¤š/åˆ©ç©ºå±•ç¤º\n",
    "# ç¨³å®šç‰ˆï¼šJSON-only + æœ¬åœ°ä¸¥æ ¼æ ¡éªŒ + è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤šNæ¬¡ï¼‰\n",
    "# æ–°å¢ï¼š\n",
    "#  1) æ›´ç¨³ä¸¤å¤„å°æ”¹åŠ¨ï¼ˆæé«˜é‡è¯•æ¬¡æ•° + ç¦æ­¢å­—ç¬¦ä¸²é‡Œå‡ºç° ASCII åŒå¼•å·ï¼‰\n",
    "#  2) å¯é€‰â€œå¼¹å‡ºçª—å£â€ï¼ˆç”¨æµè§ˆå™¨æ‰“å¼€æœ¬åœ° HTML å±•ç¤ºä¸¤ä¸ª DFï¼‰\n",
    "#  3) æ¯æ¬¡è¿è¡Œä¿å­˜ Excelï¼ˆåŒä¸€æ–‡ä»¶ä¸¤å¼  sheetï¼šåˆ©å¤š/åˆ©ç©ºï¼›æ–‡ä»¶å=æ—¶é—´æˆ³ï¼Œè‡ªåŠ¨é¿å…é‡åï¼‰\n",
    "# ==========================================\n",
    "\n",
    "# =========================\n",
    "# A) å‚æ•°åŒºï¼ˆä½ ä¸»è¦æ”¹è¿™é‡Œï¼‰\n",
    "# =========================\n",
    "CONFIG = {\n",
    "    # å®šæ—¶è¿è¡Œ\n",
    "    \"ENABLE_SCHEDULER\": False,    # True=å¾ªç¯å®šæ—¶è·‘ï¼›False=åªè·‘ä¸€æ¬¡\n",
    "    \"INTERVAL_MINUTES\": 30,       # å»ºè®® 10~20 ä¹Ÿå¯ä»¥\n",
    "\n",
    "    # çƒ­æœæŠ“å–\n",
    "    \"TOP_K\": 30,\n",
    "    \"TOUTIAO_TIMEOUT\": 12,\n",
    "\n",
    "    # åƒé—®ï¼ˆOpenAI å…¼å®¹æ¥å£ï¼‰\n",
    "    \"DASHSCOPE_API_KEY\": \"sk-b8a5d51908184663854d1b5c8e73e25e\",\n",
    "    \"QWEN_MODEL\": \"qwen-plus\",\n",
    "    \"QWEN_BASE_URL\": \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    \"QWEN_TIMEOUT\": 60,\n",
    "\n",
    "    # ç¨³å®šè¾“å‡ºå»ºè®®æ¸©åº¦ 0\n",
    "    \"TEMPERATURE\": 0.0,\n",
    "    \"MAX_TOKENS\": 1200,\n",
    "\n",
    "    # è¾“å‡ºæ§åˆ¶\n",
    "    \"MAX_ITEMS_EACH_SIDE\": 12,\n",
    "\n",
    "    # âœ… å°æ”¹åŠ¨ 1ï¼šæé«˜é‡è¯•æ¬¡æ•°ï¼ˆæ›´ç¨³ï¼‰\n",
    "    \"MAX_QWEN_RETRIES\": 10,\n",
    "    \"RETRY_SLEEP_SECONDS\": 0.6,\n",
    "\n",
    "    # è°ƒè¯•\n",
    "    \"DEBUG_SHOW_RAW_ON_FAIL\": True,   # æœ€ç»ˆå¤±è´¥æ—¶æ‰“å°åŸå§‹è¾“å‡ºç‰‡æ®µ\n",
    "\n",
    "    # ç»“æœå±•ç¤ºï¼šå¼¹å‡ºçª—å£ï¼ˆæµè§ˆå™¨æ–°çª—å£/æ–°æ ‡ç­¾æ‰“å¼€ HTMLï¼‰\n",
    "    \"ENABLE_POPUP\": True,            # True æ—¶æ¯æ¬¡è¿è¡Œå¼¹å‡º HTML çª—å£å±•ç¤ºä¸¤ä¸ª DF\n",
    "    \"POPUP_TITLE_PREFIX\": \"çƒ­æœåˆ©å¤š/åˆ©ç©ºåˆ†æ\",\n",
    "\n",
    "    # ç»“æœä¿å­˜ï¼šExcel\n",
    "    \"ENABLE_SAVE_EXCEL\": True,\n",
    "    \"OUTPUT_DIR\": \"./hotsearch_stock_outputs\",   # ä¿å­˜ç›®å½•\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# B) ä¾èµ–\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from IPython.display import display  # type: ignore\n",
    "except Exception:\n",
    "    display = None\n",
    "\n",
    "# DataFrame æ˜¾ç¤ºï¼šå…¨éƒ¨è¡Œåˆ— + å®Œæ•´å­—ç¬¦ä¸²ï¼ˆä½ è¦æ±‚æ˜¾ç¤ºå…¨éƒ¨å†…å®¹ï¼‰\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 0)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) æŠ“å–ä»Šæ—¥å¤´æ¡çƒ­æ¦œ\n",
    "# =========================\n",
    "def fetch_toutiao_hot(top_k: int = 30, timeout: int = 12) -> List[Dict[str, Any]]:\n",
    "    url = \"https://www.toutiao.com/hot-event/hot-board/?origin=toutiao_pc\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Referer\": \"https://www.toutiao.com/\",\n",
    "        \"Accept\": \"application/json,text/plain,*/*\",\n",
    "    }\n",
    "    r = requests.get(url, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    payload = r.json()\n",
    "\n",
    "    data = payload.get(\"data\")\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Unexpected response schema. Top keys: {list(payload.keys())}\")\n",
    "\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    for i, it in enumerate(data[:top_k], start=1):\n",
    "        title = it.get(\"Title\") or it.get(\"title\") or \"\"\n",
    "        hot_value = it.get(\"HotValue\") or it.get(\"hot_value\") or 0\n",
    "        link = it.get(\"Url\") or it.get(\"url\") or \"\"\n",
    "\n",
    "        try:\n",
    "            hot_value_num = float(hot_value)\n",
    "        except Exception:\n",
    "            hot_value_num = None\n",
    "\n",
    "        items.append({\n",
    "            \"rank\": i,\n",
    "            \"title\": str(title).strip(),\n",
    "            \"hot_value\": hot_value_num,\n",
    "            \"url\": str(link).strip(),\n",
    "        })\n",
    "\n",
    "    return [x for x in items if x[\"title\"]]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) åƒé—®è°ƒç”¨ï¼ˆOpenAI å…¼å®¹ chat/completionsï¼‰\n",
    "# =========================\n",
    "def qwen_chat_raw(\n",
    "    api_key: str,\n",
    "    base_url: str,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    timeout: int,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    è¿”å› (text, raw_json)\n",
    "    \"\"\"\n",
    "    endpoint = base_url.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    body: Dict[str, Any] = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        # å°½é‡æç¤ºè¾“å‡º JSONï¼ˆæ ¸å¿ƒä»é é‡è¯• + prompt çº¦æŸ + æœ¬åœ°æ ¡éªŒï¼‰\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    }\n",
    "\n",
    "    r = requests.post(endpoint, headers=headers, json=body, timeout=timeout)\n",
    "    if not r.ok:\n",
    "        raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:1500]}\")\n",
    "    raw = r.json()\n",
    "\n",
    "    msg = raw[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # æœ‰äº›å®ç°ä¼šèµ° tool_calls arguments\n",
    "    tool_calls = msg.get(\"tool_calls\")\n",
    "    if isinstance(tool_calls, list) and tool_calls:\n",
    "        fn = tool_calls[0].get(\"function\", {})\n",
    "        args = fn.get(\"arguments\")\n",
    "        if isinstance(args, str) and args.strip():\n",
    "            return args, raw\n",
    "\n",
    "    content = msg.get(\"content\")\n",
    "    if isinstance(content, str):\n",
    "        return content, raw\n",
    "\n",
    "    return json.dumps(msg, ensure_ascii=False), raw\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) JSON æ¸…ç†/è§£æ/æ ¡éªŒ\n",
    "# =========================\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.strip()\n",
    "\n",
    "    # å»æ‰ ```json``` åŒ…è£¹\n",
    "    s = re.sub(r\"^```(?:json)?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "\n",
    "    # ä¸­æ–‡å¼•å· -> è‹±æ–‡å¼•å·ï¼ˆé¿å…è§£æå¤±è´¥ï¼‰\n",
    "    s = s.replace(\"â€œ\", '\"').replace(\"â€\", '\"').replace(\"â€˜\", \"'\").replace(\"â€™\", \"'\")\n",
    "\n",
    "    # JSON ä¸å…è®¸ NaN/Infinity\n",
    "    s = re.sub(r\"\\bNaN\\b\", \"null\", s)\n",
    "    s = re.sub(r\"\\bInfinity\\b\", \"null\", s)\n",
    "    s = re.sub(r\"\\b-Infinity\\b\", \"null\", s)\n",
    "\n",
    "    # å°¾é€—å·ï¼ˆå¸¸è§ï¼‰\n",
    "    s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def strict_parse_json(s: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ä¸¥æ ¼ï¼šå¿…é¡»æ˜¯ JSON objectï¼›å¹¶ä¸”æ¸…ç†åå¿…é¡»ä»¥ { å¼€å¤´ã€} ç»“å°¾ï¼ˆé˜²æ­¢å¤¹å¸¦æ–‡æœ¬ï¼‰\n",
    "    \"\"\"\n",
    "    s2 = clean_text(s)\n",
    "    s2_strip = s2.strip()\n",
    "    if not (s2_strip.startswith(\"{\") and s2_strip.endswith(\"}\")):\n",
    "        raise ValueError(\"Output is not a pure JSON object (missing { } boundaries).\")\n",
    "\n",
    "    obj = json.loads(s2_strip)\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"JSON is not an object.\")\n",
    "    return obj\n",
    "\n",
    "\n",
    "def validate_result(obj: Dict[str, Any]) -> None:\n",
    "    for k in [\"bullish\", \"bearish\", \"ignored\"]:\n",
    "        if k not in obj:\n",
    "            raise ValueError(f\"Missing key: {k}\")\n",
    "        if not isinstance(obj[k], list):\n",
    "            raise ValueError(f\"Key '{k}' must be a list.\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Promptï¼ˆæ›´ç¡¬çº¦æŸ JSON-onlyï¼‰\n",
    "#    âœ… å°æ”¹åŠ¨ 2ï¼šç¦æ­¢å­—ç¬¦ä¸²é‡Œå‡ºç° ASCII åŒå¼•å· \"\n",
    "# =========================\n",
    "def build_messages(items: List[Dict[str, Any]], max_each_side: int) -> List[Dict[str, str]]:\n",
    "    hot_lines = []\n",
    "    for it in items:\n",
    "        hv = it[\"hot_value\"]\n",
    "        hv_str = f\"{hv:.0f}\" if isinstance(hv, (int, float)) and hv is not None else \"\"\n",
    "        hot_lines.append(f'{it[\"rank\"]}. {it[\"title\"]} (HotValue={hv_str})')\n",
    "\n",
    "    user = f\"\"\"\n",
    "ä½ ä¼šæ”¶åˆ°â€œä»Šæ—¥å¤´æ¡çƒ­æ¦œæ ‡é¢˜åˆ—è¡¨â€ã€‚è¯·åˆ¤æ–­å“ªäº›çƒ­æœå¯èƒ½å¼•èµ·è¡Œä¸š/æ¿å—å±‚é¢çš„çŸ­æœŸè‚¡ä»·æ³¢åŠ¨ã€‚\n",
    "å°†å…¶åˆ†ä¸ºï¼šbullishï¼ˆåˆ©å¤šï¼‰ã€bearishï¼ˆåˆ©ç©ºï¼‰ã€ignoredï¼ˆä¸å¤ªç›¸å…³ï¼‰ã€‚\n",
    "\n",
    "æå…¶é‡è¦çš„è¾“å‡ºè¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š\n",
    "- åªè¾“å‡ºä¸€æ®µä¸¥æ ¼ JSONï¼ˆä¸è¦ markdownã€ä¸è¦è§£é‡Šã€ä¸è¦ä»»ä½•å‰åç¼€æ–‡å­—ï¼‰ã€‚\n",
    "- è¾“å‡ºå¿…é¡»ä»¥å­—ç¬¦ \"{{\" å¼€å¤´ï¼Œå¹¶ä»¥ \"}}\" ç»“å°¾ã€‚\n",
    "- JSON ä¸­ä¸å¾—å‡ºç° NaN/Infinityã€‚\n",
    "- confidence å¿…é¡»æ˜¯ 0~1 çš„å°æ•°ï¼ˆä¸è¦ç™¾åˆ†å·ï¼‰ã€‚\n",
    "- æ¯ç»„æœ€å¤š {max_each_side} æ¡ï¼Œä¼˜å…ˆæŒ‘é€‰â€œæ”¿ç­–/ç›‘ç®¡ã€å®è§‚æ•°æ®ã€äº‹æ•…é£é™©ã€é‡å¤§äº¤æ˜“ã€ç§‘æŠ€çªç ´ã€èƒ½æº/å¤§å®—ã€åŒ»ç–—/è¯å“ã€é‡‘èé£é™©â€ç­‰æ›´å¯èƒ½å½±å“è‚¡ä»·çš„ä¸»é¢˜ã€‚\n",
    "- ä¸è¦ç¼–é€ å…·ä½“è‚¡ç¥¨ä»£ç ï¼›åªç»™è¡Œä¸š/æ¿å—ã€‚\n",
    "- ã€é‡è¦ã€‘æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µï¼ˆtopic/mechanism/reason/industriesï¼‰ä¸­ç¦æ­¢å‡ºç° ASCII åŒå¼•å·å­—ç¬¦ (\")ã€‚\n",
    "  å¦‚æœéœ€è¦è¡¨è¾¾å¼•ç”¨ï¼Œè¯·ç”¨ä¸­æ–‡å¼•å·ï¼ˆâ€œ â€ï¼‰æˆ–æ‹¬å·ï¼Œæˆ–ç”¨å•å¼•å·ï¼ˆ'ï¼‰ä»£æ›¿ã€‚\n",
    "\n",
    "å›ºå®š JSON Schemaï¼ˆå­—æ®µåå¿…é¡»ä¸€è‡´ï¼‰ï¼š\n",
    "{{\n",
    "  \"bullish\": [{{\"rank\": 1, \"topic\": \"...\", \"industries\": [\"...\"], \"mechanism\": \"...\", \"confidence\": 0.0}}],\n",
    "  \"bearish\":  [{{\"rank\": 1, \"topic\": \"...\", \"industries\": [\"...\"], \"mechanism\": \"...\", \"confidence\": 0.0}}],\n",
    "  \"ignored\":  [{{\"rank\": 1, \"topic\": \"...\", \"reason\": \"...\"}}]\n",
    "}}\n",
    "\n",
    "çƒ­æ¦œæ ‡é¢˜åˆ—è¡¨ï¼š\n",
    "{chr(10).join(hot_lines)}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸¥è°¨çš„ä¸­æ–‡é‡‘èä¿¡æ¯åˆ†æåŠ©æ‰‹ã€‚å¿…é¡»è¾“å‡ºä¸¥æ ¼ JSONã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) è‡ªåŠ¨é‡è¯•ï¼šç›´åˆ°æ‹¿åˆ°å¯è§£æ JSON æˆ–è¶…å‡ºæœ€å¤§æ¬¡æ•°\n",
    "# =========================\n",
    "def qwen_analyze_with_retries(items: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    messages = build_messages(items, CONFIG[\"MAX_ITEMS_EACH_SIDE\"])\n",
    "\n",
    "    last_text: Optional[str] = None\n",
    "    last_err: Optional[Exception] = None\n",
    "\n",
    "    for attempt in range(1, CONFIG[\"MAX_QWEN_RETRIES\"] + 1):\n",
    "        try:\n",
    "            text, raw = qwen_chat_raw(\n",
    "                api_key=CONFIG[\"DASHSCOPE_API_KEY\"],\n",
    "                base_url=CONFIG[\"QWEN_BASE_URL\"],\n",
    "                model=CONFIG[\"QWEN_MODEL\"],\n",
    "                messages=messages,\n",
    "                timeout=CONFIG[\"QWEN_TIMEOUT\"],\n",
    "                temperature=CONFIG[\"TEMPERATURE\"],\n",
    "                max_tokens=CONFIG[\"MAX_TOKENS\"],\n",
    "            )\n",
    "            last_text = text\n",
    "\n",
    "            obj = strict_parse_json(text)\n",
    "            validate_result(obj)\n",
    "            return obj\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(CONFIG[\"RETRY_SLEEP_SECONDS\"])\n",
    "\n",
    "    # å…¨å¤±è´¥ï¼šè¾“å‡ºæœ€åä¸€æ¬¡åŸå§‹æ–‡æœ¬ç‰‡æ®µè¾…åŠ©è°ƒè¯•\n",
    "    if CONFIG.get(\"DEBUG_SHOW_RAW_ON_FAIL\") and last_text:\n",
    "        print(\"\\n[DEBUG] Last model output (first 1200 chars):\")\n",
    "        print(clean_text(last_text)[:1200])\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Failed to obtain valid JSON after {CONFIG['MAX_QWEN_RETRIES']} attempts. Last error: {last_err}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) DataFrame + å±•ç¤º\n",
    "# =========================\n",
    "def to_df(lst: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    if not lst:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(lst).copy()\n",
    "    if \"industries\" in df.columns:\n",
    "        df[\"industries\"] = df[\"industries\"].apply(lambda x: \"ï¼Œ\".join(x) if isinstance(x, list) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_df(df: pd.DataFrame):\n",
    "    if display is not None:\n",
    "        display(df)\n",
    "    else:\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) å¼¹å‡ºçª—å£å±•ç¤ºï¼ˆæµè§ˆå™¨æ‰“å¼€æœ¬åœ° HTMLï¼‰\n",
    "# =========================\n",
    "def popup_show_dfs(bullish_df: pd.DataFrame, bearish_df: pd.DataFrame, title: str, output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def _df_to_html(df: pd.DataFrame) -> str:\n",
    "        if df is None or df.empty:\n",
    "            return \"<p><em>ï¼ˆæ— æ•°æ®ï¼‰</em></p>\"\n",
    "        return df.to_html(index=False, escape=True)\n",
    "\n",
    "    html = f\"\"\"\n",
    "<!doctype html>\n",
    "<html lang=\"zh\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>{title}</title>\n",
    "<style>\n",
    "body {{ font-family: -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Arial; margin: 20px; }}\n",
    "h1 {{ margin-bottom: 12px; }}\n",
    "h2 {{ margin-top: 22px; }}\n",
    "table {{ border-collapse: collapse; width: 100%; }}\n",
    "th, td {{ border: 1px solid #ddd; padding: 8px; vertical-align: top; }}\n",
    "th {{ background: #f6f6f6; }}\n",
    "tr:nth-child(even) {{ background: #fafafa; }}\n",
    ".small {{ color: #666; font-size: 12px; }}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>{title}</h1>\n",
    "<div class=\"small\">ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</div>\n",
    "\n",
    "<h2>ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰</h2>\n",
    "{_df_to_html(bullish_df)}\n",
    "\n",
    "<h2>ğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰</h2>\n",
    "{_df_to_html(bearish_df)}\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\".strip()\n",
    "\n",
    "    # ç”¨æ—¶é—´æˆ³å‘½åï¼Œé¿å…è¦†ç›–\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = os.path.abspath(os.path.join(output_dir, f\"popup_{ts}.html\"))\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    # æ‰“å¼€æµè§ˆå™¨ï¼ˆé€šå¸¸ä¼šæ–°æ ‡ç­¾/æ–°çª—å£ï¼›æµè§ˆå™¨è®¾ç½®å¯èƒ½å½±å“è¡Œä¸ºï¼‰\n",
    "    webbrowser.open(f\"file://{filepath}\", new=1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8) ä¿å­˜ Excelï¼ˆåŒä¸€æ–‡ä»¶ä¸¤å¼  sheetï¼šåˆ©å¤š/åˆ©ç©ºï¼›æ–‡ä»¶å=æ—¶é—´æˆ³ï¼Œè‡ªåŠ¨é¿å…é‡åï¼‰\n",
    "# =========================\n",
    "def save_dfs_to_excel(bullish_df: pd.DataFrame, bearish_df: pd.DataFrame, ts_str: str, output_dir: str) -> str:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    base_name = f\"hotsearch_{ts_str}.xlsx\"\n",
    "    path = os.path.join(output_dir, base_name)\n",
    "\n",
    "    # é¿å…é‡åï¼šå¦‚æœå­˜åœ¨åˆ™è¿½åŠ  _1, _2 ...\n",
    "    if os.path.exists(path):\n",
    "        i = 1\n",
    "        while True:\n",
    "            alt = os.path.join(output_dir, f\"hotsearch_{ts_str}_{i}.xlsx\")\n",
    "            if not os.path.exists(alt):\n",
    "                path = alt\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as writer:\n",
    "        # sheet åæŒ‰ä½ çš„è¦æ±‚ï¼šåˆ©å¤š/åˆ©ç©º\n",
    "        (bullish_df if bullish_df is not None else pd.DataFrame()).to_excel(writer, sheet_name=\"åˆ©å¤š\", index=False)\n",
    "        (bearish_df if bearish_df is not None else pd.DataFrame()).to_excel(writer, sheet_name=\"åˆ©ç©º\", index=False)\n",
    "\n",
    "    return os.path.abspath(path)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 9) è¿è¡Œä¸€æ¬¡\n",
    "# =========================\n",
    "def run_once() -> Dict[str, Any]:\n",
    "    items = fetch_toutiao_hot(CONFIG[\"TOP_K\"], CONFIG[\"TOUTIAO_TIMEOUT\"])\n",
    "    result = qwen_analyze_with_retries(items)\n",
    "\n",
    "    ts_display = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    ts_fname = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    bullish_df = to_df(result.get(\"bullish\", []))\n",
    "    bearish_df = to_df(result.get(\"bearish\", []))\n",
    "\n",
    "    print(f\"\\n===== Run @ {ts_display} =====\")\n",
    "    print(f\"Fetched {len(items)} hot topics. \"\n",
    "          f\"Model returned {len(result.get('bullish', []))} bullish / {len(result.get('bearish', []))} bearish.\\n\")\n",
    "\n",
    "    print(\"ğŸ“ˆ å¯èƒ½åˆ©å¤šï¼ˆæ­£é¢å‚¬åŒ–ï¼‰\")\n",
    "    show_df(bullish_df)\n",
    "\n",
    "    print(\"\\nğŸ“‰ å¯èƒ½åˆ©ç©ºï¼ˆè´Ÿé¢å†²å‡»ï¼‰\")\n",
    "    show_df(bearish_df)\n",
    "\n",
    "    # ä¿å­˜ Excel\n",
    "    if CONFIG.get(\"ENABLE_SAVE_EXCEL\"):\n",
    "        saved_path = save_dfs_to_excel(\n",
    "            bullish_df=bullish_df,\n",
    "            bearish_df=bearish_df,\n",
    "            ts_str=ts_fname,\n",
    "            output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
    "        )\n",
    "        print(f\"\\nğŸ’¾ å·²ä¿å­˜ Excelï¼š{saved_path}\")\n",
    "\n",
    "    # å¼¹å‡ºçª—å£ï¼ˆæµè§ˆå™¨ï¼‰\n",
    "    if CONFIG.get(\"ENABLE_POPUP\"):\n",
    "        title = f\"{CONFIG.get('POPUP_TITLE_PREFIX', 'çƒ­æœåˆ†æ')} - {ts_display}\"\n",
    "        popup_show_dfs(bullish_df, bearish_df, title=title, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 10) å®šæ—¶å¾ªç¯ï¼ˆå¯é€‰ï¼‰\n",
    "# =========================\n",
    "def run_scheduler():\n",
    "    interval_sec = int(CONFIG[\"INTERVAL_MINUTES\"] * 60)\n",
    "    print(f\"Scheduler started. Interval={CONFIG['INTERVAL_MINUTES']} minutes. Stop with Kernel Interrupt (â›”).\")\n",
    "    while True:\n",
    "        try:\n",
    "            run_once()\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {e}\")\n",
    "        time.sleep(interval_sec)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 11) æ‰§è¡Œå…¥å£\n",
    "# =========================\n",
    "_ = run_once()\n",
    "\n",
    "if CONFIG[\"ENABLE_SCHEDULER\"]:\n",
    "    run_scheduler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6628af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be712f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b31aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pz_py311_causal_x86",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
